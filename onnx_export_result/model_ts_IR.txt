module __torch__.ScriptableAdapter {
  parameters {
  }
  attributes {
    _is_full_backward_hook = None
    model = <__torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN object at 0x71da110>
  }
  methods {
    method forward {
      graph(%self : __torch__.ScriptableAdapter,
            %inputs.1 : (Dict(str, Tensor))):
        %12 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/tools/deploy/export_model.py:90:23
        %7 : NoneType = prim::Constant()
        %4 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/tools/deploy/export_model.py:89:72
        %model : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self)
        %5 : Dict(str, Tensor) = prim::TupleUnpack(%inputs.1)
        %6 : Dict(str, Tensor)[] = prim::ListConstruct(%5)
        %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="inference"](%model, %6, %7, %4) # /home/kelechi/detectron2/tools/deploy/export_model.py:89:28
        %9 : Dict(str, Tensor)[] = prim::ListConstruct()
        %11 : int = aten::len(%instances.1) # /home/kelechi/detectron2/tools/deploy/export_model.py:90:23
         = prim::Loop(%11, %12) # /home/kelechi/detectron2/tools/deploy/export_model.py:90:23
          block0(%13 : int):
            %i.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%instances.1, %13) # /home/kelechi/detectron2/tools/deploy/export_model.py:90:23
            %16 : Dict(str, Tensor) = prim::CallMethod[name="get_fields"](%i.1) # /home/kelechi/detectron2/tools/deploy/export_model.py:90:24
            %17 : Dict(str, Tensor)[] = aten::append(%9, %16) # /home/kelechi/detectron2/tools/deploy/export_model.py:90:23
            -> (%12)
        return (%9)
  
    }
  }
  submodules {
    module __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN {
      parameters {
      }
      attributes {
        pixel_mean = ...
        pixel_std = ...
        _is_full_backward_hook = None
        input_format = BGR
        vis_period = 0
        backbone = <__torch__.detectron2.modeling.backbone.fpn.FPN object at 0x75e2180>
        proposal_generator = <__torch__.detectron2.modeling.proposal_generator.rpn.RPN object at 0x7884820>
        roi_heads = <__torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads object at 0x7326d00>
      }
      methods {
        method __device_getter {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN):
            %pixel_mean : Tensor = prim::GetAttr[name="pixel_mean"](%self)
            %2 : Device = prim::device(%pixel_mean)
            return (%2)
      
        }
        method forward {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN,
                %batched_inputs.1 : Dict(str, Tensor)[]):
            %8 : bool = prim::Constant[value=1]()
            %7 : NoneType = prim::Constant()
            %9 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="inference"](%self, %batched_inputs.1, %7, %8) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:150:19
            return (%9)
      
        }
        method inference {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN,
                %batched_inputs.1 : Dict(str, Tensor)[],
                %detected_instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]?,
                %do_postprocess.1 : bool):
            %87 : str = prim::Constant[value="AssertionError: Scripting is not supported for postprocess."]()
            %41 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:215:33
            %15 : NoneType = prim::Constant() # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:206:33
            %images.1 : __torch__.detectron2.structures.image_list.ImageList = prim::CallMethod[name="preprocess_image"](%self, %batched_inputs.1) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:203:17
            %backbone : __torch__.detectron2.modeling.backbone.fpn.FPN = prim::GetAttr[name="backbone"](%self)
            %tensor : Tensor = prim::GetAttr[name="tensor"](%images.1)
            %features.1 : Dict(str, Tensor) = prim::CallMethod[name="forward"](%backbone, %tensor) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:204:19
            %16 : bool = aten::__is__(%detected_instances.1, %15) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:206:11
            %results : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::If(%16) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:206:8
              block0():
                %proposal_generator : __torch__.detectron2.modeling.proposal_generator.rpn.RPN = prim::GetAttr[name="proposal_generator"](%self)
                %24 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Dict(str, Tensor)) = prim::CallMethod[name="forward"](%proposal_generator, %images.1, %features.1, %15) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:208:31
                %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], %26 : Dict(str, Tensor) = prim::TupleUnpack(%24)
                %roi_heads.1 : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads = prim::GetAttr[name="roi_heads"](%self)
                %32 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Dict(str, Tensor)) = prim::CallMethod[name="forward"](%roi_heads.1, %images.1, %features.1, %proposals.1, %15) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:213:25
                %results.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], %34 : Dict(str, Tensor) = prim::TupleUnpack(%32)
                -> (%results.1)
              block1():
                %detected_instances.7 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::unchecked_cast(%detected_instances.1)
                %detected_instances.13 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::ListConstruct()
                %40 : int = aten::len(%detected_instances.7) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:215:33
                 = prim::Loop(%40, %41) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:215:33
                  block0(%42 : int):
                    %x.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%detected_instances.7, %42) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:215:33
                    %45 : Device = prim::CallMethod[name="__device_getter"](%self) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:215:39
                    %46 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = prim::CallMethod[name="to"](%x.1, %45) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:215:34
                    %47 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = aten::append(%detected_instances.13, %46) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:215:33
                    -> (%41)
                %roi_heads : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads = prim::GetAttr[name="roi_heads"](%self)
                %results.3 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="forward_with_given_boxes"](%roi_heads, %features.1, %detected_instances.13) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:216:22
                -> (%results.3)
             = prim::If(%do_postprocess.1) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:218:8
              block0():
                 = prim::RaiseException(%87, %15) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:219:12
                -> ()
              block1():
                -> ()
            return (%results)
      
        }
        method preprocess_image {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN,
                %batched_inputs.1 : Dict(str, Tensor)[]):
            %33 : Function = prim::Constant[name="from_tensors"]()
            %32 : float = prim::Constant[value=0.]()
            %22 : int = prim::Constant[value=1]()
            %10 : str = prim::Constant[value="image"]() # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:227:49
            %6 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:227:17
            %images.1 : Tensor[] = prim::ListConstruct()
            %5 : int = aten::len(%batched_inputs.1) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:227:17
             = prim::Loop(%5, %6) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:227:17
              block0(%7 : int):
                %x.1 : Dict(str, Tensor) = aten::__getitem__(%batched_inputs.1, %7) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:227:17
                %11 : Tensor = aten::__getitem__(%x.1, %10) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:227:47
                %12 : Tensor = prim::CallMethod[name="_move_to_current_device"](%self, %11) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:227:18
                %13 : Tensor[] = aten::append(%images.1, %12) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:227:17
                -> (%6)
            %images.5 : Tensor[] = prim::ListConstruct()
            %16 : int = aten::len(%images.1) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:228:17
             = prim::Loop(%16, %6) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:228:17
              block0(%18 : int):
                %x.5 : Tensor = aten::__getitem__(%images.1, %18) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:228:17
                %pixel_mean : Tensor = prim::GetAttr[name="pixel_mean"](%self)
                %23 : Tensor = aten::sub(%x.5, %pixel_mean, %22) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:228:19
                %pixel_std : Tensor = prim::GetAttr[name="pixel_std"](%self)
                %25 : Tensor = aten::div(%23, %pixel_std) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:228:19
                %26 : Tensor[] = aten::append(%images.5, %25) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:228:17
                -> (%6)
            %backbone.1 : __torch__.detectron2.modeling.backbone.fpn.FPN = prim::GetAttr[name="backbone"](%self)
            %29 : int = prim::CallMethod[name="__size_divisibility_getter"](%backbone.1) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:231:12
            %backbone : __torch__.detectron2.modeling.backbone.fpn.FPN = prim::GetAttr[name="backbone"](%self)
            %31 : Dict(str, int) = prim::CallMethod[name="__padding_constraints_getter"](%backbone) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:232:32
            %images.9 : __torch__.detectron2.structures.image_list.ImageList = prim::CallFunction(%33, %images.5, %29, %32, %31) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:229:17
            return (%images.9)
      
        }
        method _move_to_current_device {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN,
                %x.1 : Tensor):
            %4 : Function = prim::Constant[name="move_device_like"]()
            %pixel_mean : Tensor = prim::GetAttr[name="pixel_mean"](%self)
            %5 : Tensor = prim::CallFunction(%4, %x.1, %pixel_mean) # /home/kelechi/detectron2/detectron2/modeling/meta_arch/rcnn.py:89:15
            return (%5)
      
        }
      }
      submodules {
        module __torch__.detectron2.modeling.backbone.fpn.FPN {
          parameters {
          }
          attributes {
            _is_full_backward_hook = None
            in_features = (res2, res3, res4, res5)
            _out_feature_strides = {p2: 4, p3: 8, p4: 16, p5: 32, p6: 64}
            _out_features = [p2, p3, p4, p5, p6]
            _out_feature_channels = {p2: 256, p3: 256, p4: 256, p5: 256, p6: 256}
            _size_divisibility = 32
            _square_pad = 0
            top_block = <__torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool object at 0x732a3d0>
            bottom_up = <__torch__.detectron2.modeling.backbone.resnet.ResNet object at 0x732db40>
            lateral_convs = <__torch__.torch.nn.modules.container.___torch_mangle_33.ModuleList object at 0x72d90b0>
            output_convs = <__torch__.torch.nn.modules.container.___torch_mangle_35.ModuleList object at 0x75f59c0>
          }
          methods {
            method __padding_constraints_getter {
              graph(%self : __torch__.detectron2.modeling.backbone.fpn.FPN):
                %1 : str = prim::Constant[value="square_size"]() # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:124:16
                %_square_pad : int = prim::GetAttr[name="_square_pad"](%self)
                %3 : Dict(str, int) = prim::DictConstruct(%1, %_square_pad)
                return (%3)
          
            }
            method __size_divisibility_getter {
              graph(%self : __torch__.detectron2.modeling.backbone.fpn.FPN):
                %_size_divisibility : int = prim::GetAttr[name="_size_divisibility"](%self)
                return (%_size_divisibility)
          
            }
            method forward {
              graph(%self : __torch__.detectron2.modeling.backbone.fpn.FPN,
                    %x.1 : Tensor):
                %295 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:167:15
                %353 : str = prim::Constant[value="AssertionError: "]()
                %351 : int = prim::Constant[value=-4]()
                %347 : int = prim::Constant[value=-3]()
                %133 : int = prim::Constant[value=1]()
                %127 : Function = prim::Constant[name="interpolate"]()
                %126 : bool = prim::Constant[value=0]()
                %123 : NoneType = prim::Constant()
                %120 : str = prim::Constant[value="nearest"]() # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:153:88
                %343 : int = prim::Constant[value=-2]()
                %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:141:82
                %idx.1 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:141:43
                %71 : float = prim::Constant[value=2.]() # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:153:78
                %bottom_up : __torch__.detectron2.modeling.backbone.resnet.ResNet = prim::GetAttr[name="bottom_up"](%self)
                %bottom_up_features.1 : Dict(str, Tensor) = prim::CallMethod[name="forward"](%bottom_up, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:139:29
                %339 : Tensor[] = prim::ListConstruct()
                %lateral_convs.1 : __torch__.torch.nn.modules.container.___torch_mangle_33.ModuleList = prim::GetAttr[name="lateral_convs"](%self)
                %_0.1 : __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d = prim::GetAttr[name="0"](%lateral_convs.1)
                %in_features.1 : (str, str, str, str) = prim::GetAttr[name="in_features"](%self)
                %22 : str = prim::TupleIndex(%in_features.1, %21)
                %23 : Tensor = aten::__getitem__(%bottom_up_features.1, %22) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:141:46
                %prev_features.1 : Tensor = prim::CallMethod[name="forward"](%_0.1, %23) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:141:24
                %output_convs.1 : __torch__.torch.nn.modules.container.___torch_mangle_35.ModuleList = prim::GetAttr[name="output_convs"](%self)
                %_0.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%output_convs.1)
                %36 : Tensor = prim::CallMethod[name="forward"](%_0.3, %prev_features.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:142:23
                %37 : Tensor[] = aten::append(%339, %36) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:142:8
                %lateral_convs : __torch__.torch.nn.modules.container.___torch_mangle_33.ModuleList = prim::GetAttr[name="lateral_convs"](%self)
                %_1.5 : __torch__.detectron2.layers.wrappers.___torch_mangle_30.Conv2d = prim::GetAttr[name="1"](%lateral_convs)
                %_2.5 : __torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d = prim::GetAttr[name="2"](%lateral_convs)
                %_3.5 : __torch__.detectron2.layers.wrappers.___torch_mangle_32.Conv2d = prim::GetAttr[name="3"](%lateral_convs)
                %output_convs : __torch__.torch.nn.modules.container.___torch_mangle_35.ModuleList = prim::GetAttr[name="output_convs"](%self)
                %_1 : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d = prim::GetAttr[name="1"](%output_convs)
                %_2 : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d = prim::GetAttr[name="2"](%output_convs)
                %_3 : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d = prim::GetAttr[name="3"](%output_convs)
                %in_features.5 : (str, str, str, str) = prim::GetAttr[name="in_features"](%self)
                %features.9 : str = prim::TupleIndex(%in_features.5, %343)
                %features.13 : Tensor = aten::__getitem__(%bottom_up_features.1, %features.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:152:27
                %top_down_features.5 : Tensor = prim::CallFunction(%127, %prev_features.1, %123, %71, %120, %123, %123, %126) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:153:36
                %lateral_features.5 : Tensor = prim::CallMethod[name="forward"](%_1.5, %features.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:154:35
                %prev_features.37 : Tensor = aten::add(%lateral_features.5, %top_down_features.5, %133) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:155:32
                %149 : Tensor = prim::CallMethod[name="forward"](%_1, %prev_features.37) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:158:34
                 = aten::insert(%339, %idx.1, %149) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:158:16
                %in_features.7 : (str, str, str, str) = prim::GetAttr[name="in_features"](%self)
                %features.17 : str = prim::TupleIndex(%in_features.7, %347)
                %features.21 : Tensor = aten::__getitem__(%bottom_up_features.1, %features.17) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:152:27
                %top_down_features.9 : Tensor = prim::CallFunction(%127, %prev_features.37, %123, %71, %120, %123, %123, %126) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:153:36
                %lateral_features.9 : Tensor = prim::CallMethod[name="forward"](%_2.5, %features.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:154:35
                %prev_features.67 : Tensor = aten::add(%lateral_features.9, %top_down_features.9, %133) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:155:32
                %196 : Tensor = prim::CallMethod[name="forward"](%_2, %prev_features.67) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:158:34
                 = aten::insert(%339, %idx.1, %196) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:158:16
                %in_features : (str, str, str, str) = prim::GetAttr[name="in_features"](%self)
                %features.25 : str = prim::TupleIndex(%in_features, %351)
                %features.29 : Tensor = aten::__getitem__(%bottom_up_features.1, %features.25) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:152:27
                %top_down_features.13 : Tensor = prim::CallFunction(%127, %prev_features.67, %123, %71, %120, %123, %123, %126) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:153:36
                %lateral_features.13 : Tensor = prim::CallMethod[name="forward"](%_3.5, %features.29) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:154:35
                %prev_features.97 : Tensor = aten::add(%lateral_features.13, %top_down_features.13, %133) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:155:32
                %244 : Tensor = prim::CallMethod[name="forward"](%_3, %prev_features.97) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:158:34
                 = aten::insert(%339, %idx.1, %244) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:158:16
                %top_block.3 : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool = prim::GetAttr[name="top_block"](%self)
                %in_feature.1 : str = prim::GetAttr[name="in_feature"](%top_block.3)
                %256 : bool = aten::__contains__(%bottom_up_features.1, %in_feature.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:161:15
                %top_block_in_feature : Tensor = prim::If(%256) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:161:12
                  block0():
                    %top_block.5 : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool = prim::GetAttr[name="top_block"](%self)
                    %in_feature.3 : str = prim::GetAttr[name="in_feature"](%top_block.5)
                    %top_block_in_feature.1 : Tensor = aten::__getitem__(%bottom_up_features.1, %in_feature.3) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:162:39
                    -> (%top_block_in_feature.1)
                  block1():
                    %_out_features.1 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %top_block.7 : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool = prim::GetAttr[name="top_block"](%self)
                    %in_feature : str = prim::GetAttr[name="in_feature"](%top_block.7)
                    %266 : int = aten::index(%_out_features.1, %in_feature) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:164:47
                    %top_block_in_feature.3 : Tensor = aten::__getitem__(%339, %266) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:164:39
                    -> (%top_block_in_feature.3)
                %top_block : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool = prim::GetAttr[name="top_block"](%self)
                %275 : Tensor[] = prim::CallMethod[name="forward"](%top_block, %top_block_in_feature) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:165:27
                 = aten::extend(%339, %275) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:165:12
                %_out_features.3 : str[] = prim::GetAttr[name="_out_features"](%self)
                %278 : int = aten::len(%_out_features.3) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:166:15
                %280 : int = aten::len(%339) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:166:42
                %281 : bool = aten::eq(%278, %280) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:166:15
                 = prim::If(%281) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:166:8
                  block0():
                    -> ()
                  block1():
                     = prim::RaiseException(%353, %123) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:166:8
                    -> ()
                %288 : Dict(str, Tensor) = prim::DictConstruct()
                %_out_features : str[] = prim::GetAttr[name="_out_features"](%self)
                %291 : int = aten::len(%_out_features) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:167:15
                %292 : int = aten::len(%339) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:167:15
                %293 : int[] = prim::ListConstruct(%291, %292)
                %294 : int = prim::min(%293) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:167:15
                 = prim::Loop(%294, %295) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:167:15
                  block0(%296 : int):
                    %f.1 : str = aten::__getitem__(%_out_features, %296) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:167:15
                    %res.1 : Tensor = aten::__getitem__(%339, %296) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:167:15
                     = aten::_set_item(%288, %f.1, %res.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:167:15
                    -> (%295)
                return (%288)
          
            }
          }
          submodules {
            module __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                num_levels = 1
                in_feature = p5
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool,
                        %x.1 : Tensor):
                    %13 : Function = prim::Constant[name="_max_pool2d"]()
                    %11 : bool = prim::Constant[value=0]()
                    %3 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:200:44
                    %4 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:200:54
                    %5 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:200:65
                    %6 : int[] = prim::ListConstruct(%3, %3)
                    %7 : int[] = prim::ListConstruct(%4, %4)
                    %8 : int[] = prim::ListConstruct(%5, %5)
                    %10 : int[] = prim::ListConstruct(%3, %3)
                    %14 : Tensor = prim::CallFunction(%13, %x.1, %6, %7, %8, %10, %11, %11) # /home/kelechi/detectron2/detectron2/modeling/backbone/fpn.py:200:16
                    %15 : Tensor[] = prim::ListConstruct(%14)
                    return (%15)
              
                }
              }
              submodules {
              }
            }
            module __torch__.detectron2.modeling.backbone.resnet.ResNet {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                num_classes = None
                _out_feature_strides = {stem: 4, res2: 4, res3: 8, res4: 16, res5: 32}
                _out_feature_channels = {stem: 64, res2: 256, res3: 512, res4: 1024, res5: 2048}
                stage_names = (res2, res3, res4, res5)
                _out_features = [res2, res3, res4, res5]
                stem = <__torch__.detectron2.modeling.backbone.resnet.BasicStem object at 0x75f2d20>
                stages = <__torch__.torch.nn.modules.container.ModuleList object at 0x7190c50>
              }
              methods {
                method __padding_constraints_getter {
                  graph(%self : __torch__.detectron2.modeling.backbone.resnet.ResNet):
                    %2 : Dict(str, int) = prim::DictConstruct()
                    return (%2)
              
                }
                method __size_divisibility_getter {
                  graph(%self : __torch__.detectron2.modeling.backbone.resnet.ResNet):
                    %2 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/backbone/backbone.py:41:15
                    return (%2)
              
                }
                method forward {
                  graph(%self : __torch__.detectron2.modeling.backbone.resnet.ResNet,
                        %x.1 : Tensor):
                    %20 : str = prim::Constant[value="stem"]() # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:446:11
                    %14 : NoneType = prim::Constant()
                    %12 : str = prim::Constant[value="AssertionError: "]() # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:443:8
                    %8 : str = prim::Constant[value="ResNet takes an input of shape (N, C, H, W). Got {} instead!"]() # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:443:29
                    %5 : int = prim::Constant[value=4]() # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:443:26
                    %4 : int = aten::dim(%x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:443:15
                    %6 : bool = aten::eq(%4, %5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:443:15
                     = prim::If(%6) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:443:8
                      block0():
                        -> ()
                      block1():
                        %10 : int[] = aten::size(%x.1) # <string>:13:9
                        %11 : str = aten::format(%8, %10) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:443:29
                        %13 : str = aten::add(%12, %11) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:443:8
                         = prim::RaiseException(%13, %14) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:443:8
                        -> ()
                    %outputs.1 : Dict(str, Tensor) = prim::DictConstruct()
                    %stem : __torch__.detectron2.modeling.backbone.resnet.BasicStem = prim::GetAttr[name="stem"](%self)
                    %x.9 : Tensor = prim::CallMethod[name="forward"](%stem, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:445:12
                    %_out_features.1 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %22 : bool = aten::__contains__(%_out_features.1, %20) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:446:11
                     = prim::If(%22) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:446:8
                      block0():
                         = aten::_set_item(%outputs.1, %20, %x.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:447:12
                        -> ()
                      block1():
                        -> ()
                    %stage_names : (str, str, str, str) = prim::GetAttr[name="stage_names"](%self)
                    %name.1 : str, %name.7 : str, %name.13 : str, %name.19 : str = prim::TupleUnpack(%stage_names)
                    %stages : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="stages"](%self)
                    %_0 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="0"](%stages)
                    %_1 : __torch__.torch.nn.modules.container.___torch_mangle_12.Sequential = prim::GetAttr[name="1"](%stages)
                    %_2 : __torch__.torch.nn.modules.container.___torch_mangle_20.Sequential = prim::GetAttr[name="2"](%stages)
                    %_3 : __torch__.torch.nn.modules.container.___torch_mangle_28.Sequential = prim::GetAttr[name="3"](%stages)
                    %x.15 : Tensor = prim::CallMethod[name="forward"](%_0, %x.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:449:16
                    %_out_features.3 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %47 : bool = aten::__contains__(%_out_features.3, %name.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:450:15
                     = prim::If(%47) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:450:12
                      block0():
                         = aten::_set_item(%outputs.1, %name.1, %x.15) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:451:16
                        -> ()
                      block1():
                        -> ()
                    %x.21 : Tensor = prim::CallMethod[name="forward"](%_1, %x.15) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:449:16
                    %_out_features.5 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %58 : bool = aten::__contains__(%_out_features.5, %name.7) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:450:15
                     = prim::If(%58) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:450:12
                      block0():
                         = aten::_set_item(%outputs.1, %name.7, %x.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:451:16
                        -> ()
                      block1():
                        -> ()
                    %x.27 : Tensor = prim::CallMethod[name="forward"](%_2, %x.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:449:16
                    %_out_features.7 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %69 : bool = aten::__contains__(%_out_features.7, %name.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:450:15
                     = prim::If(%69) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:450:12
                      block0():
                         = aten::_set_item(%outputs.1, %name.13, %x.27) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:451:16
                        -> ()
                      block1():
                        -> ()
                    %x.33 : Tensor = prim::CallMethod[name="forward"](%_3, %x.27) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:449:16
                    %_out_features : str[] = prim::GetAttr[name="_out_features"](%self)
                    %80 : bool = aten::__contains__(%_out_features, %name.19) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:450:15
                     = prim::If(%80) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:450:12
                      block0():
                         = aten::_set_item(%outputs.1, %name.19, %x.33) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:451:16
                        -> ()
                      block1():
                        -> ()
                    return (%outputs.1)
              
                }
              }
              submodules {
                module __torch__.detectron2.modeling.backbone.resnet.BasicStem {
                  parameters {
                  }
                  attributes {
                    _is_full_backward_hook = None
                    in_channels = 3
                    out_channels = 64
                    stride = 4
                    conv1 = <__torch__.detectron2.layers.wrappers.Conv2d object at 0x732cd50>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.modeling.backbone.resnet.BasicStem,
                            %x.1 : Tensor):
                        %18 : Function = prim::Constant[name="_max_pool2d"]()
                        %16 : bool = prim::Constant[value=0]()
                        %8 : int = prim::Constant[value=3]() # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:358:40
                        %9 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:358:50
                        %10 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:358:61
                        %conv1 : __torch__.detectron2.layers.wrappers.Conv2d = prim::GetAttr[name="conv1"](%self)
                        %x.5 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:356:12
                        %x.9 : Tensor = aten::relu_(%x.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:357:12
                        %11 : int[] = prim::ListConstruct(%8, %8)
                        %12 : int[] = prim::ListConstruct(%9, %9)
                        %13 : int[] = prim::ListConstruct(%10, %10)
                        %15 : int[] = prim::ListConstruct(%10, %10)
                        %x.13 : Tensor = prim::CallFunction(%18, %x.9, %11, %12, %13, %15, %16, %16) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:358:12
                        return (%x.13)
                  
                    }
                  }
                  submodules {
                    module __torch__.detectron2.layers.wrappers.Conv2d {
                      parameters {
                        weight = ...
                      }
                      attributes {
                        weight = ...
                        bias = None
                        training = False
                        _is_full_backward_hook = None
                        transposed = False
                        _reversed_padding_repeated_twice = [3, 3, 3, 3]
                        activation = None
                        norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x732e1e0>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.wrappers.Conv2d,
                                %x.1 : Tensor):
                            %14 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:66
                            %11 : int = prim::Constant[value=3]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                            %8 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                            %18 : int[] = prim::ListConstruct(%8, %8)
                            %19 : int[] = prim::ListConstruct(%11, %11)
                            %20 : int[] = prim::ListConstruct(%14, %14)
                            %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                            %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                            %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                            return (%x.9)
                      
                        }
                      }
                      submodules {
                        module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                          parameters {
                          }
                          attributes {
                            weight = ...
                            bias = ...
                            running_mean = ...
                            running_var = ...
                            num_batches_tracked = None
                            _is_full_backward_hook = None
                            num_features = 64
                            eps = 1.0000000000000001e-05
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                    %x.1 : Tensor):
                                %55 : Function = prim::Constant[name="batch_norm"]()
                                %54 : float = prim::Constant[value=0.10000000000000001]()
                                %36 : NoneType = prim::Constant()
                                %34 : bool = prim::Constant[value=0]()
                                %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                %3 : bool = prim::requires_grad(%x.1)
                                %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                  block0():
                                    %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                    %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                    %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                    %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                    %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                    %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                    %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                    %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                    %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                    %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                    %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                    %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                    %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                    %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                    %out_dtype.1 : int = prim::dtype(%x.1)
                                    %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                    %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                    %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                    %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                    -> (%46)
                                  block1():
                                    %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                    %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                    %eps : float = prim::GetAttr[name="eps"](%self)
                                    %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                    -> (%56)
                                return (%65)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.torch.nn.modules.container.ModuleList {
                  parameters {
                  }
                  attributes {
                    _is_full_backward_hook = None
                    0 = <__torch__.torch.nn.modules.container.Sequential object at 0x9340730>
                    1 = <__torch__.torch.nn.modules.container.___torch_mangle_12.Sequential object at 0x719e6b0>
                    2 = <__torch__.torch.nn.modules.container.___torch_mangle_20.Sequential object at 0x7192860>
                    3 = <__torch__.torch.nn.modules.container.___torch_mangle_28.Sequential object at 0x76291e0>
                  }
                  methods {
                    method __len__ {
                      graph(%self : __torch__.torch.nn.modules.container.ModuleList):
                        %1 : int = prim::Constant[value=4]() # <string>:2:10
                        return (%1)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.Sequential {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.modeling.backbone.resnet.BottleneckBlock object at 0x7626500>
                        1 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_4.BottleneckBlock object at 0x719ba20>
                        2 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_4.BottleneckBlock object at 0x7608b60>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.container.Sequential,
                                %input.1 : Tensor):
                            %_0 : __torch__.detectron2.modeling.backbone.resnet.BottleneckBlock = prim::GetAttr[name="0"](%self)
                            %_1 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_4.BottleneckBlock = prim::GetAttr[name="1"](%self)
                            %_2 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_4.BottleneckBlock = prim::GetAttr[name="2"](%self)
                            %input.5 : Tensor = prim::CallMethod[name="forward"](%_0, %input.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.9 : Tensor = prim::CallMethod[name="forward"](%_1, %input.5) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.13 : Tensor = prim::CallMethod[name="forward"](%_2, %input.9) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            return (%input.13)
                      
                        }
                        method __len__ {
                          graph(%self : __torch__.torch.nn.modules.container.Sequential):
                            %1 : int = prim::Constant[value=3]() # <string>:2:10
                            return (%1)
                      
                        }
                      }
                      submodules {
                        module __torch__.detectron2.modeling.backbone.resnet.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 64
                            out_channels = 256
                            stride = 1
                            shortcut = <__torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d object at 0x7629df0>
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d object at 0x761f750>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d object at 0x760e580>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d object at 0x7617e50>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.BottleneckBlock,
                                    %x.1 : Tensor):
                                %23 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %shortcut.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d = prim::GetAttr[name="shortcut"](%self)
                                %shortcut.5 : Tensor = prim::CallMethod[name="forward"](%shortcut.3, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:204:23
                                %out.21 : Tensor = aten::add_(%out.17, %shortcut.5, %23) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7191bd0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x760eeb0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 64
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7196b50>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 64
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x719c390>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_4.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 256
                            out_channels = 256
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d object at 0x719d2d0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d object at 0x76069c0>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d object at 0x7185200>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_4.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7606a30>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 64
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71939d0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 64
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7186710>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_4.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 256
                            out_channels = 256
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d object at 0x71a3d10>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d object at 0x71a4e10>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d object at 0x762c190>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_4.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x719e820>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 64
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x760a860>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 64
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71a2520>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_0.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_12.Sequential {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_9.BottleneckBlock object at 0x71af0b0>
                        1 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock object at 0x71adc10>
                        2 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock object at 0x733c8c0>
                        3 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock object at 0x733f970>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_12.Sequential,
                                %input.1 : Tensor):
                            %_0 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_9.BottleneckBlock = prim::GetAttr[name="0"](%self)
                            %_1 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock = prim::GetAttr[name="1"](%self)
                            %_2 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock = prim::GetAttr[name="2"](%self)
                            %_3 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock = prim::GetAttr[name="3"](%self)
                            %input.5 : Tensor = prim::CallMethod[name="forward"](%_0, %input.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.9 : Tensor = prim::CallMethod[name="forward"](%_1, %input.5) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.13 : Tensor = prim::CallMethod[name="forward"](%_2, %input.9) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.17 : Tensor = prim::CallMethod[name="forward"](%_3, %input.13) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            return (%input.17)
                      
                        }
                        method __len__ {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_12.Sequential):
                            %1 : int = prim::Constant[value=4]() # <string>:2:10
                            return (%1)
                      
                        }
                      }
                      submodules {
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_9.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 256
                            out_channels = 512
                            stride = 2
                            shortcut = <__torch__.detectron2.layers.wrappers.___torch_mangle_5.Conv2d object at 0x71ad0f0>
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_6.Conv2d object at 0x75fe980>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d object at 0x71b6270>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d object at 0x71a8320>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_9.BottleneckBlock,
                                    %x.1 : Tensor):
                                %23 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_6.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %shortcut.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_5.Conv2d = prim::GetAttr[name="shortcut"](%self)
                                %shortcut.5 : Tensor = prim::CallMethod[name="forward"](%shortcut.3, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:204:23
                                %out.21 : Tensor = aten::add_(%out.17, %shortcut.5, %23) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_5.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7600290>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_5.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:66
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_6.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71b3340>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_6.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:66
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 128
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71aa6a0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 128
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71bb850>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 512
                            out_channels = 512
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d object at 0x71c1170>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d object at 0x71c1100>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d object at 0x7342e80>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71add70>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 128
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7341a40>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 128
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7337ee0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 512
                            out_channels = 512
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d object at 0x733d390>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d object at 0x71c2290>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d object at 0x761ce00>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x733ca30>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 128
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71c38a0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 128
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71b9130>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 512
                            out_channels = 512
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d object at 0x733e790>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d object at 0x7338250>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d object at 0x734a0d0>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_11.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71a9bd0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 128
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71a9b10>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 128
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x718dc40>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_8.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_20.Sequential {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_17.BottleneckBlock object at 0x71b9a00>
                        1 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock object at 0x7339a30>
                        2 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock object at 0x733c350>
                        3 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock object at 0x732d560>
                        4 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock object at 0x7374c90>
                        5 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock object at 0x72b7c60>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_20.Sequential,
                                %input.1 : Tensor):
                            %_0 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_17.BottleneckBlock = prim::GetAttr[name="0"](%self)
                            %_1 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock = prim::GetAttr[name="1"](%self)
                            %_2 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock = prim::GetAttr[name="2"](%self)
                            %_3 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock = prim::GetAttr[name="3"](%self)
                            %_4 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock = prim::GetAttr[name="4"](%self)
                            %_5 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock = prim::GetAttr[name="5"](%self)
                            %input.5 : Tensor = prim::CallMethod[name="forward"](%_0, %input.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.9 : Tensor = prim::CallMethod[name="forward"](%_1, %input.5) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.13 : Tensor = prim::CallMethod[name="forward"](%_2, %input.9) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.17 : Tensor = prim::CallMethod[name="forward"](%_3, %input.13) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.21 : Tensor = prim::CallMethod[name="forward"](%_4, %input.17) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.25 : Tensor = prim::CallMethod[name="forward"](%_5, %input.21) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            return (%input.25)
                      
                        }
                        method __len__ {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_20.Sequential):
                            %1 : int = prim::Constant[value=6]() # <string>:2:10
                            return (%1)
                      
                        }
                      }
                      submodules {
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_17.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 512
                            out_channels = 1024
                            stride = 2
                            shortcut = <__torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d object at 0x7616fb0>
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_14.Conv2d object at 0x7354ac0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d object at 0x7354830>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d object at 0x7347350>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_17.BottleneckBlock,
                                    %x.1 : Tensor):
                                %23 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_14.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %shortcut.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d = prim::GetAttr[name="shortcut"](%self)
                                %shortcut.5 : Tensor = prim::CallMethod[name="forward"](%shortcut.3, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:204:23
                                %out.21 : Tensor = aten::add_(%out.17, %shortcut.5, %23) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71aab60>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:66
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 1024
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_14.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7351bf0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_14.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:66
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x73537c0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x735b380>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 1024
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d object at 0x73611c0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d object at 0x73639d0>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d object at 0x73698f0>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x735dc90>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x73684b0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x736b160>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 1024
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d object at 0x71bc6b0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d object at 0x71a7fb0>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d object at 0x75ff880>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x733b610>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x73423d0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x736ad40>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 1024
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d object at 0x7374d80>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d object at 0x7188290>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d object at 0x760d270>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x735f600>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7619030>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7374b20>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 1024
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d object at 0x7345e50>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d object at 0x7370990>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d object at 0x75ff810>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x734eb10>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x73550b0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7344c90>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 1024
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d object at 0x72bc0c0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d object at 0x7602d70>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d object at 0x735bed0>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_19.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7606400>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71c2e50>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_15.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 256
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x736f630>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_16.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 1024
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_28.Sequential {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_25.BottleneckBlock object at 0x735d290>
                        1 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_27.BottleneckBlock object at 0x72c2c30>
                        2 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_27.BottleneckBlock object at 0x72e08b0>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_28.Sequential,
                                %input.1 : Tensor):
                            %_0 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_25.BottleneckBlock = prim::GetAttr[name="0"](%self)
                            %_1 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_27.BottleneckBlock = prim::GetAttr[name="1"](%self)
                            %_2 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_27.BottleneckBlock = prim::GetAttr[name="2"](%self)
                            %input.5 : Tensor = prim::CallMethod[name="forward"](%_0, %input.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.9 : Tensor = prim::CallMethod[name="forward"](%_1, %input.5) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            %input.13 : Tensor = prim::CallMethod[name="forward"](%_2, %input.9) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/container.py:219:20
                            return (%input.13)
                      
                        }
                        method __len__ {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_28.Sequential):
                            %1 : int = prim::Constant[value=3]() # <string>:2:10
                            return (%1)
                      
                        }
                      }
                      submodules {
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_25.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 2048
                            stride = 2
                            shortcut = <__torch__.detectron2.layers.wrappers.___torch_mangle_21.Conv2d object at 0x736e520>
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d object at 0x72cabd0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d object at 0x72c5a30>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d object at 0x736c720>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_25.BottleneckBlock,
                                    %x.1 : Tensor):
                                %23 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %shortcut.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_21.Conv2d = prim::GetAttr[name="shortcut"](%self)
                                %shortcut.5 : Tensor = prim::CallMethod[name="forward"](%shortcut.3, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:204:23
                                %out.21 : Tensor = aten::add_(%out.17, %shortcut.5, %23) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_21.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71b5520>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_21.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:66
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 2048
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x72cee30>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:66
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x72b7990>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x72bd720>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 2048
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_27.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 2048
                            out_channels = 2048
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d object at 0x72ca430>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d object at 0x72db250>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d object at 0x72e0f90>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_27.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x7346db0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x72df970>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x72d6050>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 2048
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_27.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 2048
                            out_channels = 2048
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d object at 0x72c2450>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d object at 0x72c6970>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d object at 0x72ccf50>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_27.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/kelechi/detectron2/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71bc360>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x73500f0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_23.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 512
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d object at 0x71c3fc0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_24.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                                    %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                                    %norm : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:146:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d {
                                  parameters {
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = None
                                    _is_full_backward_hook = None
                                    num_features = 2048
                                    eps = 1.0000000000000001e-05
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.detectron2.layers.batch_norm.FrozenBatchNorm2d,
                                            %x.1 : Tensor):
                                        %55 : Function = prim::Constant[name="batch_norm"]()
                                        %54 : float = prim::Constant[value=0.10000000000000001]()
                                        %36 : NoneType = prim::Constant()
                                        %34 : bool = prim::Constant[value=0]()
                                        %21 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:37
                                        %19 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:34
                                        %3 : bool = prim::requires_grad(%x.1)
                                        %65 : Tensor = prim::If(%3) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:46:8
                                          block0():
                                            %weight.1 : Tensor = prim::GetAttr[name="weight"](%self)
                                            %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %eps.1 : float = prim::GetAttr[name="eps"](%self)
                                            %9 : Tensor = aten::add(%running_var.1, %eps.1, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %10 : Tensor = aten::rsqrt(%9) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:35
                                            %scale.1 : Tensor = aten::mul(%weight.1, %10) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:49:20
                                            %bias.1 : Tensor = prim::GetAttr[name="bias"](%self)
                                            %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %15 : Tensor = aten::mul(%running_mean.1, %scale.1) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:31
                                            %bias.3 : Tensor = aten::sub(%bias.1, %15, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:50:19
                                            %22 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %scale.7 : Tensor = aten::reshape(%scale.1, %22) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:51:20
                                            %27 : int[] = prim::ListConstruct(%19, %21, %19, %19)
                                            %bias.7 : Tensor = aten::reshape(%bias.3, %27) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:52:19
                                            %out_dtype.1 : int = prim::dtype(%x.1)
                                            %37 : Tensor = aten::to(%scale.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:23
                                            %38 : Tensor = aten::mul(%x.1, %37) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            %44 : Tensor = aten::to(%bias.7, %out_dtype.1, %34, %34, %36) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:45
                                            %46 : Tensor = aten::add(%38, %44, %19) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:54:19
                                            -> (%46)
                                          block1():
                                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                            %eps : float = prim::GetAttr[name="eps"](%self)
                                            %56 : Tensor = prim::CallFunction(%55, %x.1, %running_mean, %running_var, %weight, %bias, %34, %54, %eps) # /home/kelechi/detectron2/detectron2/layers/batch_norm.py:58:19
                                            -> (%56)
                                        return (%65)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
            module __torch__.torch.nn.modules.container.___torch_mangle_33.ModuleList {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                0 = <__torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d object at 0x72eccb0>
                1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_30.Conv2d object at 0x72e8b20>
                2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d object at 0x72f0b40>
                3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_32.Conv2d object at 0x72e7200>
              }
              methods {
                method __len__ {
                  graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_33.ModuleList):
                    %1 : int = prim::Constant[value=4]() # <string>:2:10
                    return (%1)
              
                }
              }
              submodules {
                module __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_30.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_30.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_32.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_32.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
            module __torch__.torch.nn.modules.container.___torch_mangle_35.ModuleList {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                0 = <__torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d object at 0x71b0f50>
                1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d object at 0x72f32b0>
                2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d object at 0x74d9ba0>
                3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d object at 0x74db9a0>
              }
              methods {
                method __len__ {
                  graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_35.ModuleList):
                    %1 : int = prim::Constant[value=4]() # <string>:2:10
                    return (%1)
              
                }
              }
              submodules {
                module __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
          }
        }
        module __torch__.detectron2.modeling.proposal_generator.rpn.RPN {
          parameters {
          }
          attributes {
            _is_full_backward_hook = None
            in_features = [p2, p3, p4, p5, p6]
            anchor_matcher = <__torch__.detectron2.modeling.matcher.Matcher object at 0x7879120>
            box2box_transform = <__torch__.detectron2.modeling.box_regression.Box2BoxTransform object at 0x74e9d20>
            batch_size_per_image = 256
            positive_fraction = 0.5
            pre_nms_topk = {True: 2000, False: 1000}
            post_nms_topk = {True: 1000, False: 1000}
            nms_thresh = 0.69999999999999996
            min_box_size = 0.
            anchor_boundary_thresh = -1
            loss_weight = {loss_rpn_cls: 1., loss_rpn_loc: 1.}
            box_reg_loss_type = smooth_l1
            smooth_l1_beta = 0.
            rpn_head = <__torch__.detectron2.modeling.proposal_generator.rpn.StandardRPNHead object at 0x9624300>
            anchor_generator = <__torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator object at 0x78a8a40>
          }
          methods {
            method forward {
              graph(%self : __torch__.detectron2.modeling.proposal_generator.rpn.RPN,
                    %images.1 : __torch__.detectron2.structures.image_list.ImageList,
                    %features.1 : Dict(str, Tensor),
                    %gt_instances : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]?):
                %56 : int = prim::Constant[value=-2]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:463:74
                %36 : int = prim::Constant[value=-1]()
                %8 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:451:19
                %30 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:458:26
                %31 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:458:29
                %32 : int = prim::Constant[value=3]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:458:32
                %33 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:458:35
                %65 : int = prim::Constant[value=4]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:464:27
                %features.5 : Tensor[] = prim::ListConstruct()
                %in_features : str[] = prim::GetAttr[name="in_features"](%self)
                %7 : int = aten::len(%in_features) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:451:19
                 = prim::Loop(%7, %8) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:451:19
                  block0(%9 : int):
                    %f.1 : str = aten::__getitem__(%in_features, %9) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:451:19
                    %13 : Tensor = aten::__getitem__(%features.1, %f.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:451:20
                    %14 : Tensor[] = aten::append(%features.5, %13) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:451:19
                    -> (%8)
                %anchor_generator.1 : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator = prim::GetAttr[name="anchor_generator"](%self)
                %anchors.1 : __torch__.detectron2.structures.boxes.Boxes[] = prim::CallMethod[name="forward"](%anchor_generator.1, %features.5) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:452:18
                %rpn_head : __torch__.detectron2.modeling.proposal_generator.rpn.StandardRPNHead = prim::GetAttr[name="rpn_head"](%self)
                %20 : (Tensor[], Tensor[]) = prim::CallMethod[name="forward"](%rpn_head, %features.5) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:454:53
                %pred_objectness_logits.1 : Tensor[], %pred_anchor_deltas.1 : Tensor[] = prim::TupleUnpack(%20)
                %pred_objectness_logits.5 : Tensor[] = prim::ListConstruct()
                %25 : int = aten::len(%pred_objectness_logits.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:456:33
                 = prim::Loop(%25, %8) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:456:33
                  block0(%27 : int):
                    %score.1 : Tensor = aten::__getitem__(%pred_objectness_logits.1, %27) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:456:33
                    %34 : int[] = prim::ListConstruct(%30, %31, %32, %33)
                    %35 : Tensor = aten::permute(%score.1, %34) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:458:12
                    %37 : Tensor = aten::flatten(%35, %33, %36) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:458:12
                    %38 : Tensor[] = aten::append(%pred_objectness_logits.5, %37) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:456:33
                    -> (%8)
                %pred_anchor_deltas.5 : Tensor[] = prim::ListConstruct()
                %41 : int = aten::len(%pred_anchor_deltas.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:461:29
                 = prim::Loop(%41, %8) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:461:29
                  block0(%43 : int):
                    %x.1 : Tensor = aten::__getitem__(%pred_anchor_deltas.1, %43) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:461:29
                    %47 : int[] = aten::size(%x.1) # <string>:13:9
                    %48 : int = aten::__getitem__(%47, %30) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:463:19
                    %54 : int[] = aten::size(%x.1) # <string>:13:9
                    %57 : int = aten::__getitem__(%54, %56) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:463:66
                    %59 : int[] = aten::size(%x.1) # <string>:13:9
                    %62 : int = aten::__getitem__(%59, %36) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:463:79
                    %63 : int[] = prim::ListConstruct(%48, %36, %65, %57, %62)
                    %64 : Tensor = aten::view(%x.1, %63) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:463:12
                    %66 : int[] = prim::ListConstruct(%30, %32, %65, %33, %31)
                    %67 : Tensor = aten::permute(%64, %66) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:463:12
                    %70 : Tensor = aten::flatten(%67, %33, %56) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:463:12
                    %71 : Tensor[] = aten::append(%pred_anchor_deltas.5, %70) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:461:29
                    -> (%8)
                %losses.1 : Dict(str, Tensor) = prim::DictConstruct()
                %image_sizes : (int, int)[] = prim::GetAttr[name="image_sizes"](%images.1)
                %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="predict_proposals"](%self, %anchors.1, %pred_objectness_logits.5, %pred_anchor_deltas.5, %image_sizes) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:477:20
                %83 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Dict(str, Tensor)) = prim::TupleConstruct(%proposals.1, %losses.1)
                return (%83)
          
            }
            method predict_proposals {
              graph(%self : __torch__.detectron2.modeling.proposal_generator.rpn.RPN,
                    %anchors.1 : __torch__.detectron2.structures.boxes.Boxes[],
                    %pred_objectness_logits.1 : Tensor[],
                    %pred_anchor_deltas.1 : Tensor[],
                    %image_sizes.1 : (int, int)[]):
                %24 : Function = prim::Constant[name="find_top_rpn_proposals"]()
                %17 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:508:34
                %6 : __torch__.torch.autograd.grad_mode.no_grad = prim::CreateObject() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:501:13
                %7 : NoneType = prim::CallMethod[name="__init__"](%6) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:501:13
                %8 : NoneType = prim::Enter(%6)
                %pred_proposals.1 : Tensor[] = prim::CallMethod[name="_decode_proposals"](%self, %anchors.1, %pred_anchor_deltas.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:502:29
                %nms_thresh : float = prim::GetAttr[name="nms_thresh"](%self)
                %pre_nms_topk : Dict(bool, int) = prim::GetAttr[name="pre_nms_topk"](%self)
                %18 : int = aten::__getitem__(%pre_nms_topk, %17) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:508:16
                %post_nms_topk : Dict(bool, int) = prim::GetAttr[name="post_nms_topk"](%self)
                %21 : int = aten::__getitem__(%post_nms_topk, %17) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:509:16
                %min_box_size : float = prim::GetAttr[name="min_box_size"](%self)
                %25 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallFunction(%24, %pred_proposals.1, %pred_objectness_logits.1, %image_sizes.1, %nms_thresh, %18, %21, %min_box_size, %17) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:503:19
                %26 : Tensor = prim::Exit(%6)
                return (%25)
          
            }
            method _decode_proposals {
              graph(%self : __torch__.detectron2.modeling.proposal_generator.rpn.RPN,
                    %anchors.1 : __torch__.detectron2.structures.boxes.Boxes[],
                    %pred_anchor_deltas.1 : Tensor[]):
                %40 : bool = prim::Constant[value=0]()
                %27 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:527:64
                %16 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:525:8
                %5 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:522:31
                %23 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:526:38
                %6 : Tensor = aten::__getitem__(%pred_anchor_deltas.1, %5) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:522:12
                %7 : int[] = aten::size(%6) # <string>:13:9
                %N.1 : int = aten::__getitem__(%7, %5) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:522:12
                %70 : Tensor[] = prim::ListConstruct()
                %12 : int = aten::len(%anchors.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:525:8
                %13 : int = aten::len(%pred_anchor_deltas.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:525:8
                %14 : int[] = prim::ListConstruct(%12, %13)
                %15 : int = prim::min(%14) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:525:8
                 = prim::Loop(%15, %16) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:525:8
                  block0(%17 : int):
                    %anchors_i.1 : __torch__.detectron2.structures.boxes.Boxes = aten::__getitem__(%anchors.1, %17) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:525:8
                    %pred_anchor_deltas_i.1 : Tensor = aten::__getitem__(%pred_anchor_deltas.1, %17) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:525:8
                    %tensor.1 : Tensor = prim::GetAttr[name="tensor"](%anchors_i.1)
                    %B.1 : int = aten::size(%tensor.1, %23) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:526:16
                    %29 : int[] = prim::ListConstruct(%27, %B.1)
                    %pred_anchor_deltas_i.5 : Tensor = aten::reshape(%pred_anchor_deltas_i.1, %29) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:527:35
                    %tensor : Tensor = prim::GetAttr[name="tensor"](%anchors_i.1)
                    %33 : Tensor = aten::unsqueeze(%tensor, %5) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:529:24
                    %39 : int[] = prim::ListConstruct(%N.1, %27, %27)
                    %41 : Tensor = aten::expand(%33, %39, %40) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:529:24
                    %45 : int[] = prim::ListConstruct(%27, %B.1)
                    %anchors_i.7 : Tensor = aten::reshape(%41, %45) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:529:24
                    %box2box_transform : __torch__.detectron2.modeling.box_regression.Box2BoxTransform = prim::GetAttr[name="box2box_transform"](%self)
                    %proposals_i.1 : Tensor = prim::CallMethod[name="apply_deltas"](%box2box_transform, %pred_anchor_deltas_i.5, %anchors_i.7) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:530:26
                    %57 : int[] = prim::ListConstruct(%N.1, %27, %B.1)
                    %58 : Tensor = aten::view(%proposals_i.1, %57) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:532:29
                    %59 : Tensor[] = aten::append(%70, %58) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:532:12
                    -> (%16)
                return (%70)
          
            }
          }
          submodules {
            module __torch__.detectron2.modeling.proposal_generator.rpn.StandardRPNHead {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                conv = <__torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d object at 0x962a320>
                objectness_logits = <__torch__.torch.nn.modules.conv.Conv2d object at 0x7886be0>
                anchor_deltas = <__torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d object at 0x7538e30>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.proposal_generator.rpn.StandardRPNHead,
                        %features.1 : Tensor[]):
                    %7 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:173:8
                    %35 : Tensor[] = prim::ListConstruct()
                    %36 : Tensor[] = prim::ListConstruct()
                    %6 : int = aten::len(%features.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:173:8
                     = prim::Loop(%6, %7) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:173:8
                      block0(%8 : int):
                        %x.1 : Tensor = aten::__getitem__(%features.1, %8) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:173:8
                        %conv : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d = prim::GetAttr[name="conv"](%self)
                        %t.1 : Tensor = prim::CallMethod[name="forward"](%conv, %x.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:174:16
                        %objectness_logits : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="objectness_logits"](%self)
                        %16 : Tensor = prim::CallMethod[name="forward"](%objectness_logits, %t.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:175:42
                        %17 : Tensor[] = aten::append(%35, %16) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:175:12
                        %anchor_deltas : __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d = prim::GetAttr[name="anchor_deltas"](%self)
                        %21 : Tensor = prim::CallMethod[name="forward"](%anchor_deltas, %t.1) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:176:38
                        %22 : Tensor[] = aten::append(%36, %21) # /home/kelechi/detectron2/detectron2/modeling/proposal_generator/rpn.py:176:12
                        -> (%7)
                    %25 : (Tensor[], Tensor[]) = prim::TupleConstruct(%35, %36)
                    return (%25)
              
                }
              }
              submodules {
                module __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0x73325f0>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:148:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.torch.nn.modules.conv.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.conv.Conv2d,
                            %input.1 : Tensor):
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %5 : Tensor = prim::CallMethod[name="_conv_forward"](%self, %input.1, %weight, %bias) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:458:15
                        return (%5)
                  
                    }
                    method _conv_forward {
                      graph(%self : __torch__.torch.nn.modules.conv.Conv2d,
                            %input.1 : Tensor,
                            %weight.1 : Tensor,
                            %bias.1 : Tensor?):
                        %61 : int = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:455:24
                        %58 : int = prim::Constant[value=1]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:454:45
                        %68 : int[] = prim::ListConstruct(%58, %58)
                        %69 : int[] = prim::ListConstruct(%61, %61)
                        %70 : int[] = prim::ListConstruct(%58, %58)
                        %71 : Tensor = aten::conv2d(%input.1, %weight.1, %bias.1, %68, %69, %70, %58) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:454:15
                        return (%71)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d,
                            %input.1 : Tensor):
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %5 : Tensor = prim::CallMethod[name="_conv_forward"](%self, %input.1, %weight, %bias) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:458:15
                        return (%5)
                  
                    }
                    method _conv_forward {
                      graph(%self : __torch__.torch.nn.modules.conv.___torch_mangle_37.Conv2d,
                            %input.1 : Tensor,
                            %weight.1 : Tensor,
                            %bias.1 : Tensor?):
                        %61 : int = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:455:24
                        %58 : int = prim::Constant[value=1]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:454:45
                        %68 : int[] = prim::ListConstruct(%58, %58)
                        %69 : int[] = prim::ListConstruct(%61, %61)
                        %70 : int[] = prim::ListConstruct(%58, %58)
                        %71 : Tensor = aten::conv2d(%input.1, %weight.1, %bias.1, %68, %69, %70, %58) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:454:15
                        return (%71)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                strides = [4, 8, 16, 32, 64]
                num_features = 5
                offset = 0.
                cell_anchors = <__torch__.detectron2.modeling.anchor_generator.BufferList object at 0x74ed780>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator,
                        %features.1 : Tensor[]):
                    %15 : NoneType = prim::Constant()
                    %14 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:229:22
                    %13 : int = prim::Constant[value=-2]() # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:229:40
                    %6 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:229:21
                    %grid_sizes.1 : int[][] = prim::ListConstruct()
                    %5 : int = aten::len(%features.1) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:229:21
                     = prim::Loop(%5, %6) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:229:21
                      block0(%7 : int):
                        %feature_map.1 : Tensor = aten::__getitem__(%features.1, %7) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:229:21
                        %10 : int[] = aten::size(%feature_map.1) # <string>:13:9
                        %16 : int[] = aten::slice(%10, %13, %15, %14) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:229:22
                        %17 : int[][] = aten::append(%grid_sizes.1, %16) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:229:21
                        -> (%6)
                    %anchors_over_all_feature_maps.1 : Tensor[] = prim::CallMethod[name="_grid_anchors"](%self, %grid_sizes.1) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:230:40
                    %20 : __torch__.detectron2.structures.boxes.Boxes[] = prim::ListConstruct()
                    %22 : int = aten::len(%anchors_over_all_feature_maps.1) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:231:15
                     = prim::Loop(%22, %6) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:231:15
                      block0(%24 : int):
                        %x.1 : Tensor = aten::__getitem__(%anchors_over_all_feature_maps.1, %24) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:231:15
                        %27 : __torch__.detectron2.structures.boxes.Boxes = prim::CreateObject() # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:231:16
                        %28 : NoneType = prim::CallMethod[name="__init__"](%27, %x.1) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:231:16
                        %29 : __torch__.detectron2.structures.boxes.Boxes[] = aten::append(%20, %27) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:231:15
                        -> (%6)
                    return (%20)
              
                }
                method _grid_anchors {
                  graph(%self : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator,
                        %grid_sizes.1 : int[][]):
                    %78 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:177:40
                    %64 : Function = prim::Constant[name="_create_grid_offsets"]()
                    %54 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:173:8
                    %23 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:172:41
                    %41 : int = prim::Constant[value=4]() # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:172:38
                    %103 : Tensor[] = prim::ListConstruct()
                    %buffers.1 : Tensor[] = prim::ListConstruct()
                    %cell_anchors : __torch__.detectron2.modeling.anchor_generator.BufferList = prim::GetAttr[name="cell_anchors"](%self)
                    %_0 : Tensor = prim::GetAttr[name="0"](%cell_anchors)
                    %_1 : Tensor = prim::GetAttr[name="1"](%cell_anchors)
                    %_2 : Tensor = prim::GetAttr[name="2"](%cell_anchors)
                    %_3 : Tensor = prim::GetAttr[name="3"](%cell_anchors)
                    %_4 : Tensor = prim::GetAttr[name="4"](%cell_anchors)
                    %26 : Tensor[] = aten::append(%buffers.1, %_0) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:172:38
                    %30 : Tensor[] = aten::append(%buffers.1, %_1) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:172:38
                    %35 : Tensor[] = aten::append(%buffers.1, %_2) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:172:38
                    %40 : Tensor[] = aten::append(%buffers.1, %_3) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:172:38
                    %45 : Tensor[] = aten::append(%buffers.1, %_4) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:172:38
                    %strides : int[] = prim::GetAttr[name="strides"](%self)
                    %49 : int = aten::len(%grid_sizes.1) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:173:8
                    %50 : int = aten::len(%strides) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:173:8
                    %51 : int = aten::len(%buffers.1) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:173:8
                    %52 : int[] = prim::ListConstruct(%49, %50, %51)
                    %53 : int = prim::min(%52) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:173:8
                     = prim::Loop(%53, %54) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:173:8
                      block0(%55 : int):
                        %size.1 : int[] = aten::__getitem__(%grid_sizes.1, %55) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:173:8
                        %stride.1 : int = aten::__getitem__(%strides, %55) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:173:8
                        %base_anchors.1 : Tensor = aten::__getitem__(%buffers.1, %55) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:173:8
                        %offset : float = prim::GetAttr[name="offset"](%self)
                        %65 : (Tensor, Tensor) = prim::CallFunction(%64, %size.1, %stride.1, %offset, %base_anchors.1) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:174:31
                        %shift_x.1 : Tensor, %shift_y.1 : Tensor = prim::TupleUnpack(%65)
                        %73 : Tensor[] = prim::ListConstruct(%shift_x.1, %shift_y.1, %shift_x.1, %shift_y.1)
                        %shifts.1 : Tensor = aten::stack(%73, %23) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:175:21
                        %79 : int[] = prim::ListConstruct(%78, %23, %41)
                        %80 : Tensor = aten::view(%shifts.1, %79) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:177:28
                        %84 : int[] = prim::ListConstruct(%23, %78, %41)
                        %85 : Tensor = aten::view(%base_anchors.1, %84) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:177:52
                        %87 : Tensor = aten::add(%80, %85, %23) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:177:28
                        %90 : int[] = prim::ListConstruct(%78, %41)
                        %91 : Tensor = aten::reshape(%87, %90) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:177:28
                        %92 : Tensor[] = aten::append(%103, %91) # /home/kelechi/detectron2/detectron2/modeling/anchor_generator.py:177:12
                        -> (%54)
                    return (%103)
              
                }
              }
              submodules {
                module __torch__.detectron2.modeling.anchor_generator.BufferList {
                  parameters {
                  }
                  attributes {
                    0 = ...
                    1 = ...
                    2 = ...
                    3 = ...
                    4 = ...
                    _is_full_backward_hook = None
                  }
                  methods {
                  }
                  submodules {
                  }
                }
              }
            }
          }
        }
        module __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads {
          parameters {
          }
          attributes {
            _is_full_backward_hook = None
            batch_size_per_image = 128
            positive_fraction = 0.25
            num_classes = 14
            proposal_matcher = <__torch__.detectron2.modeling.matcher.Matcher object at 0x756d930>
            proposal_append_gt = True
            in_features = [p2, p3, p4, p5]
            box_in_features = [p2, p3, p4, p5]
            mask_in_features = [p2, p3, p4, p5]
            train_on_pred_boxes = False
            box_pooler = <__torch__.detectron2.modeling.poolers.ROIPooler object at 0x7555850>
            box_head = <__torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead object at 0x78794d0>
            box_predictor = <__torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers object at 0x74123a0>
            mask_pooler = <__torch__.detectron2.modeling.poolers.ROIPooler object at 0x789c3c0>
            mask_head = <__torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead object at 0x753cd30>
          }
          methods {
            method forward {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %images : __torch__.detectron2.structures.image_list.ImageList,
                    %features.1 : Dict(str, Tensor),
                    %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[],
                    %targets : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]?):
                %pred_instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="_forward_box"](%self, %features.1, %proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:747:29
                %pred_instances.5 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="forward_with_given_boxes"](%self, %features.1, %pred_instances.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:750:29
                %17 : Dict(str, Tensor) = prim::DictConstruct()
                %18 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Dict(str, Tensor)) = prim::TupleConstruct(%pred_instances.5, %17)
                return (%18)
          
            }
            method _forward_box {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %features.1 : Dict(str, Tensor),
                    %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                %7 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:797:19
                %features.5 : Tensor[] = prim::ListConstruct()
                %box_in_features : str[] = prim::GetAttr[name="box_in_features"](%self)
                %6 : int = aten::len(%box_in_features) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:797:19
                 = prim::Loop(%6, %7) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:797:19
                  block0(%8 : int):
                    %f.1 : str = aten::__getitem__(%box_in_features, %8) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:797:19
                    %12 : Tensor = aten::__getitem__(%features.1, %f.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:797:20
                    %13 : Tensor[] = aten::append(%features.5, %12) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:797:19
                    -> (%7)
                %box_pooler : __torch__.detectron2.modeling.poolers.ROIPooler = prim::GetAttr[name="box_pooler"](%self)
                %16 : __torch__.detectron2.structures.boxes.Boxes[] = prim::ListConstruct()
                %18 : int = aten::len(%proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:798:49
                 = prim::Loop(%18, %7) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:798:49
                  block0(%20 : int):
                    %x.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %20) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:798:49
                    %23 : __torch__.detectron2.structures.boxes.Boxes = prim::CallMethod[name="__proposal_boxes_getter"](%x.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:798:50
                    %24 : __torch__.detectron2.structures.boxes.Boxes[] = aten::append(%16, %23) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:798:49
                    -> (%7)
                %box_features.1 : Tensor = prim::CallMethod[name="forward"](%box_pooler, %features.5, %16) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:798:23
                %box_head : __torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead = prim::GetAttr[name="box_head"](%self)
                %box_features.5 : Tensor = prim::CallMethod[name="forward"](%box_head, %box_features.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:799:23
                %box_predictor.1 : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers = prim::GetAttr[name="box_predictor"](%self)
                %predictions.1 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%box_predictor.1, %box_features.5) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:800:22
                %box_predictor : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers = prim::GetAttr[name="box_predictor"](%self)
                %37 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Tensor[]) = prim::CallMethod[name="inference"](%box_predictor, %predictions.1, %proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:815:32
                %pred_instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], %39 : Tensor[] = prim::TupleUnpack(%37)
                return (%pred_instances.1)
          
            }
            method forward_with_given_boxes {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %features.1 : Dict(str, Tensor),
                    %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                %27 : NoneType = prim::Constant()
                %45 : str = prim::Constant[value="AssertionError: "]()
                %22 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:15
                %19 : str = prim::Constant[value="pred_classes"]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:67
                %12 : str = prim::Constant[value="pred_boxes"]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:32
                %8 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:25
                %11 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%instances.1, %8) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:15
                %13 : bool = prim::CallMethod[name="has"](%11, %12) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:15
                %23 : bool = prim::If(%13) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:15
                  block0():
                    %18 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%instances.1, %8) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:50
                    %20 : bool = prim::CallMethod[name="has"](%18, %19) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:50
                    -> (%20)
                  block1():
                    -> (%22)
                 = prim::If(%23) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:8
                  block0():
                    -> ()
                  block1():
                     = prim::RaiseException(%45, %27) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:774:8
                    -> ()
                %instances.13 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="_forward_mask"](%self, %features.1, %instances.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:776:20
                %instances.17 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="_forward_keypoint"](%self, %features.1, %instances.13) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:777:20
                return (%instances.17)
          
            }
            method _forward_mask {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %features.1 : Dict(str, Tensor),
                    %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                %15 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:841:23
                %features.5 : Tensor[] = prim::ListConstruct()
                %mask_in_features : str[] = prim::GetAttr[name="mask_in_features"](%self)
                %14 : int = aten::len(%mask_in_features) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:841:23
                 = prim::Loop(%14, %15) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:841:23
                  block0(%16 : int):
                    %f.1 : str = aten::__getitem__(%mask_in_features, %16) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:841:23
                    %20 : Tensor = aten::__getitem__(%features.1, %f.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:841:24
                    %21 : Tensor[] = aten::append(%features.5, %20) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:841:23
                    -> (%15)
                %boxes.1 : __torch__.detectron2.structures.boxes.Boxes[] = prim::ListConstruct()
                %24 : int = aten::len(%instances.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:842:20
                 = prim::Loop(%24, %15) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:842:20
                  block0(%26 : int):
                    %x.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%instances.1, %26) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:842:20
                    %31 : __torch__.detectron2.structures.boxes.Boxes = prim::CallMethod[name="__pred_boxes_getter"](%x.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:842:60
                    %32 : __torch__.detectron2.structures.boxes.Boxes[] = aten::append(%boxes.1, %31) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:842:20
                    -> (%15)
                %mask_pooler : __torch__.detectron2.modeling.poolers.ROIPooler = prim::GetAttr[name="mask_pooler"](%self)
                %features.9 : Tensor = prim::CallMethod[name="forward"](%mask_pooler, %features.5, %boxes.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:843:23
                %mask_head : __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead = prim::GetAttr[name="mask_head"](%self)
                %40 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="forward"](%mask_head, %features.9, %instances.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/roi_heads.py:846:15
                return (%40)
          
            }
            method _forward_keypoint {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %features : Dict(str, Tensor),
                    %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                return (%instances.1)
          
            }
          }
          submodules {
            module __torch__.detectron2.modeling.poolers.ROIPooler {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                output_size = (7, 7)
                min_level = 2
                max_level = 5
                canonical_level = 4
                canonical_box_size = 224
                level_poolers = <__torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList object at 0x9667ea0>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.poolers.ROIPooler,
                        %x.1 : Tensor[],
                        %box_lists.1 : __torch__.detectron2.structures.boxes.Boxes[]):
                    %366 : bool = prim::Constant[value=0]()
                    %357 : Function = prim::Constant[name="nonzero_tuple"]()
                    %335 : Function = prim::Constant[name="assign_boxes_to_levels"]()
                    %237 : Function = prim::Constant[name="convert_boxes_to_pooler_format"]()
                    %65 : Function = prim::Constant[name="_create_zeros"]()
                    %54 : NoneType = prim::Constant() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:33
                    %41 : str = prim::Constant[value="unequal value, x[0] batch dim 0 is {}, but box_list has length {}"]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:236:12
                    %32 : Function = prim::Constant[name="assert_fx_safe"]()
                    %27 : str = prim::Constant[value="unequal value, num_level_assignments={}, but x is list of {} Tensors"]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:230:12
                    %6 : Function = prim::Constant[name="is_fx_tracing"]()
                    %level.1 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:32
                    %level.7 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:50
                    %level.13 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:257:8
                    %level.19 : int = prim::Constant[value=3]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:257:8
                    %level_poolers.1 : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                    %num_level_assignments.1 : int = prim::CallMethod[name="__len__"](%level_poolers.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:221:32
                    %7 : bool = prim::CallFunction(%6) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:223:15
                    %9 : bool = aten::__not__(%7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:223:11
                    %x : Tensor[] = prim::If(%9) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:223:8
                      block0():
                        %x.7 : Tensor[] = prim::unchecked_cast(%x.1)
                        -> (%x.7)
                      block1():
                        -> (%x.1)
                    %24 : int = aten::len(%x) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:229:12
                    %26 : bool = aten::eq(%24, %num_level_assignments.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:229:12
                    %30 : int = aten::len(%x) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:231:39
                    %31 : str = aten::format(%27, %num_level_assignments.1, %30) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:230:12
                    %33 : Tensor = prim::CallFunction(%32, %26, %31) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:228:8
                    %35 : int = aten::len(%box_lists.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:12
                    %38 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:30
                    %39 : int = aten::size(%38, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:30
                    %40 : bool = aten::eq(%35, %39) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:12
                    %43 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:237:16
                    %44 : int = aten::size(%43, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:237:16
                    %46 : int = aten::len(%box_lists.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:237:30
                    %47 : str = aten::format(%41, %44, %46) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:236:12
                    %49 : Tensor = prim::CallFunction(%32, %40, %47) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:234:8
                    %51 : int = aten::len(%box_lists.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:240:11
                    %52 : bool = aten::eq(%51, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:240:11
                    %330 : Tensor = prim::If(%52) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:240:8
                      block0():
                        %56 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:39
                        %57 : int[] = aten::size(%56) # <string>:13:9
                        %59 : int = aten::__getitem__(%57, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:39
                        %output_size.1 : (int, int) = prim::GetAttr[name="output_size"](%self)
                        %61 : int, %62 : int = prim::TupleUnpack(%output_size.1)
                        %64 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:73
                        %66 : Tensor = prim::CallFunction(%65, %54, %59, %61, %62, %64) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:19
                        -> (%66)
                      block1():
                        %pooler_fmt_boxes.13 : Tensor = prim::CallFunction(%237, %box_lists.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:243:27
                        %239 : bool = aten::eq(%num_level_assignments.1, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:245:11
                        %405 : Tensor = prim::If(%239) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:245:8
                          block0():
                            %level_poolers.5 : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                            %_0.3 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers.5)
                            %252 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:246:41
                            %253 : Tensor = prim::CallMethod[name="forward"](%_0.3, %252, %pooler_fmt_boxes.13) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:246:19
                            -> (%253)
                          block1():
                            %min_level.5 : int = prim::GetAttr[name="min_level"](%self)
                            %max_level.5 : int = prim::GetAttr[name="max_level"](%self)
                            %canonical_box_size.5 : int = prim::GetAttr[name="canonical_box_size"](%self)
                            %canonical_level.5 : int = prim::GetAttr[name="canonical_level"](%self)
                            %level_assignments.13 : Tensor = prim::CallFunction(%335, %box_lists.1, %min_level.5, %max_level.5, %canonical_box_size.5, %canonical_level.5) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:248:28
                            %337 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:252:23
                            %338 : int[] = aten::size(%337) # <string>:13:9
                            %num_channels.7 : int = aten::__getitem__(%338, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:252:23
                            %output_size.17 : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %output_size.21 : int = prim::TupleIndex(%output_size.17, %level.1)
                            %342 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:255:89
                            %output.15 : Tensor = prim::CallFunction(%65, %pooler_fmt_boxes.13, %num_channels.7, %output_size.21, %output_size.21, %342) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:255:17
                            %level_poolers.13 : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                            %_0.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers.13)
                            %_1.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="1"](%level_poolers.13)
                            %_2.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="2"](%level_poolers.13)
                            %_3.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="3"](%level_poolers.13)
                            %356 : Tensor = aten::eq(%level_assignments.13, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:33
                            %358 : Tensor[] = prim::CallFunction(%357, %356) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %inds.55 : Tensor = aten::__getitem__(%358, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %360 : Tensor?[] = prim::ListConstruct(%inds.55)
                            %pooler_fmt_boxes_level.31 : Tensor = aten::index(%pooler_fmt_boxes.13, %360) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:259:37
                            %363 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:46
                            %364 : Tensor = prim::CallMethod[name="forward"](%_0.11, %363, %pooler_fmt_boxes_level.31) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:39
                            %365 : Tensor?[] = prim::ListConstruct(%inds.55)
                            %367 : Tensor = aten::index_put_(%output.15, %365, %364, %366) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:12
                            %368 : Tensor = aten::eq(%level_assignments.13, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:33
                            %370 : Tensor[] = prim::CallFunction(%357, %368) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %inds.59 : Tensor = aten::__getitem__(%370, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %372 : Tensor?[] = prim::ListConstruct(%inds.59)
                            %pooler_fmt_boxes_level.35 : Tensor = aten::index(%pooler_fmt_boxes.13, %372) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:259:37
                            %375 : Tensor = aten::__getitem__(%x, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:46
                            %376 : Tensor = prim::CallMethod[name="forward"](%_1.11, %375, %pooler_fmt_boxes_level.35) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:39
                            %377 : Tensor?[] = prim::ListConstruct(%inds.59)
                            %379 : Tensor = aten::index_put_(%output.15, %377, %376, %366) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:12
                            %380 : Tensor = aten::eq(%level_assignments.13, %level.13) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:33
                            %382 : Tensor[] = prim::CallFunction(%357, %380) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %inds.63 : Tensor = aten::__getitem__(%382, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %384 : Tensor?[] = prim::ListConstruct(%inds.63)
                            %pooler_fmt_boxes_level.39 : Tensor = aten::index(%pooler_fmt_boxes.13, %384) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:259:37
                            %387 : Tensor = aten::__getitem__(%x, %level.13) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:46
                            %388 : Tensor = prim::CallMethod[name="forward"](%_2.11, %387, %pooler_fmt_boxes_level.39) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:39
                            %389 : Tensor?[] = prim::ListConstruct(%inds.63)
                            %391 : Tensor = aten::index_put_(%output.15, %389, %388, %366) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:12
                            %392 : Tensor = aten::eq(%level_assignments.13, %level.19) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:33
                            %394 : Tensor[] = prim::CallFunction(%357, %392) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %inds.67 : Tensor = aten::__getitem__(%394, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %396 : Tensor?[] = prim::ListConstruct(%inds.67)
                            %pooler_fmt_boxes_level.43 : Tensor = aten::index(%pooler_fmt_boxes.13, %396) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:259:37
                            %399 : Tensor = aten::__getitem__(%x, %level.19) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:46
                            %400 : Tensor = prim::CallMethod[name="forward"](%_3.11, %399, %pooler_fmt_boxes_level.43) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:39
                            %401 : Tensor?[] = prim::ListConstruct(%inds.67)
                            %403 : Tensor = aten::index_put_(%output.15, %401, %400, %366) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:12
                            -> (%output.15)
                        -> (%405)
                    return (%330)
              
                }
              }
              submodules {
                module __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList {
                  parameters {
                  }
                  attributes {
                    _is_full_backward_hook = None
                    0 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x9644e30>
                    1 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x73bf6a0>
                    2 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x96551c0>
                    3 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x74e7de0>
                  }
                  methods {
                    method __len__ {
                      graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList):
                        %1 : int = prim::Constant[value=4]() # <string>:2:10
                        return (%1)
                  
                    }
                  }
                  submodules {
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (7, 7)
                        spatial_scale = 0.25
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %47 : Function = prim::Constant[name="roi_align"]()
                            %20 : NoneType = prim::Constant()
                            %61 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%61, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %23 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%23) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %35 : int = prim::dtype(%input)
                            %39 : Tensor = aten::to(%rois.1, %35, %15, %15, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %44 : int, %45 : int = prim::TupleUnpack(%output_size)
                            %46 : int[] = prim::ListConstruct(%44, %45)
                            %48 : Tensor = prim::CallFunction(%47, %input, %39, %46, %spatial_scale, %sampling_ratio, %aligned) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:58:15
                            return (%48)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (7, 7)
                        spatial_scale = 0.125
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %47 : Function = prim::Constant[name="roi_align"]()
                            %20 : NoneType = prim::Constant()
                            %61 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%61, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %23 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%23) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %35 : int = prim::dtype(%input)
                            %39 : Tensor = aten::to(%rois.1, %35, %15, %15, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %44 : int, %45 : int = prim::TupleUnpack(%output_size)
                            %46 : int[] = prim::ListConstruct(%44, %45)
                            %48 : Tensor = prim::CallFunction(%47, %input, %39, %46, %spatial_scale, %sampling_ratio, %aligned) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:58:15
                            return (%48)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (7, 7)
                        spatial_scale = 0.0625
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %47 : Function = prim::Constant[name="roi_align"]()
                            %20 : NoneType = prim::Constant()
                            %61 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%61, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %23 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%23) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %35 : int = prim::dtype(%input)
                            %39 : Tensor = aten::to(%rois.1, %35, %15, %15, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %44 : int, %45 : int = prim::TupleUnpack(%output_size)
                            %46 : int[] = prim::ListConstruct(%44, %45)
                            %48 : Tensor = prim::CallFunction(%47, %input, %39, %46, %spatial_scale, %sampling_ratio, %aligned) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:58:15
                            return (%48)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (7, 7)
                        spatial_scale = 0.03125
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %47 : Function = prim::Constant[name="roi_align"]()
                            %20 : NoneType = prim::Constant()
                            %61 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%61, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %23 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%23) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %35 : int = prim::dtype(%input)
                            %39 : Tensor = aten::to(%rois.1, %35, %15, %15, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %44 : int, %45 : int = prim::TupleUnpack(%output_size)
                            %46 : int[] = prim::ListConstruct(%44, %45)
                            %48 : Tensor = prim::CallFunction(%47, %input, %39, %46, %spatial_scale, %sampling_ratio, %aligned) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:58:15
                            return (%48)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                _output_size = 1024
                flatten = <__torch__.torch.nn.modules.flatten.Flatten object at 0x75beaa0>
                fc1 = <__torch__.torch.nn.modules.linear.Linear object at 0x75c2400>
                fc_relu1 = <__torch__.torch.nn.modules.activation.ReLU object at 0x75b2b50>
                fc2 = <__torch__.torch.nn.modules.linear.___torch_mangle_39.Linear object at 0x7596a50>
                fc_relu2 = <__torch__.torch.nn.modules.activation.ReLU object at 0x757ce30>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead,
                        %x.1 : Tensor):
                    %flatten : __torch__.torch.nn.modules.flatten.Flatten = prim::GetAttr[name="flatten"](%self)
                    %fc1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="fc1"](%self)
                    %fc_relu1 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="fc_relu1"](%self)
                    %fc2 : __torch__.torch.nn.modules.linear.___torch_mangle_39.Linear = prim::GetAttr[name="fc2"](%self)
                    %fc_relu2 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="fc_relu2"](%self)
                    %x.5 : Tensor = prim::CallMethod[name="forward"](%flatten, %x.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/box_head.py:96:16
                    %x.9 : Tensor = prim::CallMethod[name="forward"](%fc1, %x.5) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/box_head.py:96:16
                    %x.13 : Tensor = prim::CallMethod[name="forward"](%fc_relu1, %x.9) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/box_head.py:96:16
                    %x.17 : Tensor = prim::CallMethod[name="forward"](%fc2, %x.13) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/box_head.py:96:16
                    %x.21 : Tensor = prim::CallMethod[name="forward"](%fc_relu2, %x.17) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/box_head.py:96:16
                    return (%x.21)
              
                }
                method __len__ {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead):
                    %1 : int = prim::Constant[value=5]() # <string>:2:10
                    return (%1)
              
                }
              }
              submodules {
                module __torch__.torch.nn.modules.flatten.Flatten {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.flatten.Flatten,
                            %input.1 : Tensor):
                        %4 : int = prim::Constant[value=-1]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/flatten.py:50:45
                        %3 : int = prim::Constant[value=1]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/flatten.py:50:29
                        %5 : Tensor = aten::flatten(%input.1, %3, %4) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/flatten.py:50:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.linear.Linear {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.linear.Linear,
                            %input.1 : Tensor):
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                        %5 : Tensor = aten::linear(%input.1, %weight, %bias) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/linear.py:117:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.activation.ReLU {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                            %input.1 : Tensor):
                        %4 : Function = prim::Constant[name="relu"]()
                        %3 : bool = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:37
                        %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.linear.___torch_mangle_39.Linear {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.linear.___torch_mangle_39.Linear,
                            %input.1 : Tensor):
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                        %5 : Tensor = aten::linear(%input.1, %weight, %bias) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/linear.py:117:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.activation.ReLU {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                            %input.1 : Tensor):
                        %4 : Function = prim::Constant[name="relu"]()
                        %3 : bool = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:37
                        %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                num_classes = 14
                box2box_transform = <__torch__.detectron2.modeling.box_regression.Box2BoxTransform object at 0x74368f0>
                smooth_l1_beta = 0.
                test_score_thresh = 0.5
                test_nms_thresh = 0.5
                test_topk_per_image = 100
                box_reg_loss_type = smooth_l1
                loss_weight = {loss_box_reg: 1.}
                use_fed_loss = False
                use_sigmoid_ce = False
                fed_loss_num_classes = 50
                cls_score = <__torch__.torch.nn.modules.linear.___torch_mangle_40.Linear object at 0x7557930>
                bbox_pred = <__torch__.torch.nn.modules.linear.___torch_mangle_41.Linear object at 0x73c3e60>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers,
                        %x.1 : Tensor):
                    %10 : int = prim::Constant[value=-1]()
                    %5 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:301:21
                    %9 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:302:43
                    %4 : int = aten::dim(%x.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:301:11
                    %6 : bool = aten::gt(%4, %5) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:301:11
                    %x : Tensor = prim::If(%6) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:301:8
                      block0():
                        %x.7 : Tensor = aten::flatten(%x.1, %9, %10) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:302:16
                        -> (%x.7)
                      block1():
                        -> (%x.1)
                    %cls_score : __torch__.torch.nn.modules.linear.___torch_mangle_40.Linear = prim::GetAttr[name="cls_score"](%self)
                    %scores.1 : Tensor = prim::CallMethod[name="forward"](%cls_score, %x) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:303:17
                    %bbox_pred : __torch__.torch.nn.modules.linear.___torch_mangle_41.Linear = prim::GetAttr[name="bbox_pred"](%self)
                    %proposal_deltas.1 : Tensor = prim::CallMethod[name="forward"](%bbox_pred, %x) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:304:26
                    %25 : (Tensor, Tensor) = prim::TupleConstruct(%scores.1, %proposal_deltas.1)
                    return (%25)
              
                }
                method inference {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers,
                        %predictions.1 : (Tensor, Tensor),
                        %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                    %25 : Function = prim::Constant[name="fast_rcnn_inference"]()
                    %13 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                    %boxes.1 : Tensor[] = prim::CallMethod[name="predict_boxes"](%self, %predictions.1, %proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:476:16
                    %scores.1 : Tensor[] = prim::CallMethod[name="predict_probs"](%self, %predictions.1, %proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:477:17
                    %image_shapes.1 : (int, int)[] = prim::ListConstruct()
                    %12 : int = aten::len(%proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                     = prim::Loop(%12, %13) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                      block0(%14 : int):
                        %x.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %14) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                        %image_size : (int, int) = prim::GetAttr[name="image_size"](%x.1)
                        %18 : (int, int)[] = aten::append(%image_shapes.1, %image_size) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                        -> (%13)
                    %test_score_thresh : float = prim::GetAttr[name="test_score_thresh"](%self)
                    %test_nms_thresh : float = prim::GetAttr[name="test_nms_thresh"](%self)
                    %test_topk_per_image : int = prim::GetAttr[name="test_topk_per_image"](%self)
                    %26 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Tensor[]) = prim::CallFunction(%25, %boxes.1, %scores.1, %image_shapes.1, %test_score_thresh, %test_nms_thresh, %test_topk_per_image) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:479:15
                    return (%26)
              
                }
                method predict_boxes {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers,
                        %predictions.1 : (Tensor, Tensor),
                        %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                    %74 : Function = prim::Constant[name="cat"]()
                    %61 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                    %32 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:542:79
                    %5 : int = aten::len(%proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:538:15
                    %7 : bool = aten::Bool(%5) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:538:15
                    %8 : bool = aten::__not__(%7) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:538:11
                    %81 : Tensor[] = prim::If(%8) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:538:8
                      block0():
                        %82 : Tensor[] = prim::ListConstruct()
                        -> (%82)
                      block1():
                        %57 : Tensor, %proposal_deltas.3 : Tensor = prim::TupleUnpack(%predictions.1)
                        %num_prop_per_image.3 : int[] = prim::ListConstruct()
                        %60 : int = aten::len(%proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                         = prim::Loop(%60, %61) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                          block0(%62 : int):
                            %p.7 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %62) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                            %64 : int = prim::CallMethod[name="__len__"](%p.7) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:541:30
                            %65 : int[] = aten::append(%num_prop_per_image.3, %64) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                            -> (%61)
                        %66 : Tensor[] = prim::ListConstruct()
                        %67 : int = aten::len(%proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:542:29
                         = prim::Loop(%67, %61) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:542:29
                          block0(%69 : int):
                            %p.11 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %69) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:542:29
                            %71 : __torch__.detectron2.structures.boxes.Boxes = prim::CallMethod[name="__proposal_boxes_getter"](%p.11) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:542:30
                            %tensor.1 : Tensor = prim::GetAttr[name="tensor"](%71)
                            %73 : Tensor[] = aten::append(%66, %tensor.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:542:29
                            -> (%61)
                        %proposal_boxes.3 : Tensor = prim::CallFunction(%74, %66, %32) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:542:25
                        %box2box_transform.1 : __torch__.detectron2.modeling.box_regression.Box2BoxTransform = prim::GetAttr[name="box2box_transform"](%self)
                        %predict_boxes.3 : Tensor = prim::CallMethod[name="apply_deltas"](%box2box_transform.1, %proposal_deltas.3, %proposal_boxes.3) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:543:24
                        %79 : Tensor[] = aten::split(%predict_boxes.3, %num_prop_per_image.3, %32) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:547:15
                        -> (%79)
                    return (%81)
              
                }
                method predict_probs {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers,
                        %predictions.1 : (Tensor, Tensor),
                        %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                    %26 : Function = prim::Constant[name="softmax"]()
                    %25 : NoneType = prim::Constant()
                    %24 : int = prim::Constant[value=3]()
                    %23 : int = prim::Constant[value=-1]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:568:42
                    %10 : bool = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                    %34 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:569:51
                    %scores.1 : Tensor, %6 : Tensor = prim::TupleUnpack(%predictions.1)
                    %num_inst_per_image.1 : int[] = prim::ListConstruct()
                    %9 : int = aten::len(%proposals.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                     = prim::Loop(%9, %10) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                      block0(%11 : int):
                        %p.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %11) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                        %14 : int = prim::CallMethod[name="__len__"](%p.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:564:30
                        %15 : int[] = aten::append(%num_inst_per_image.1, %14) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                        -> (%10)
                    %use_sigmoid_ce : bool = prim::GetAttr[name="use_sigmoid_ce"](%self)
                    %probs : Tensor = prim::If(%use_sigmoid_ce) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:565:8
                      block0():
                        %probs.1 : Tensor = aten::sigmoid(%scores.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:566:20
                        -> (%probs.1)
                      block1():
                        %probs.3 : Tensor = prim::CallFunction(%26, %scores.1, %23, %24, %25) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:568:20
                        -> (%probs.3)
                    %35 : Tensor[] = aten::split(%probs, %num_inst_per_image.1, %34) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/fast_rcnn.py:569:15
                    return (%35)
              
                }
              }
              submodules {
                module __torch__.torch.nn.modules.linear.___torch_mangle_40.Linear {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.linear.___torch_mangle_40.Linear,
                            %input.1 : Tensor):
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                        %5 : Tensor = aten::linear(%input.1, %weight, %bias) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/linear.py:117:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.linear.___torch_mangle_41.Linear {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.linear.___torch_mangle_41.Linear,
                            %input.1 : Tensor):
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                        %5 : Tensor = aten::linear(%input.1, %weight, %bias) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/linear.py:117:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.poolers.ROIPooler {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                output_size = (14, 14)
                min_level = 2
                max_level = 5
                canonical_level = 4
                canonical_box_size = 224
                level_poolers = <__torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList object at 0x73741d0>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.poolers.ROIPooler,
                        %x.1 : Tensor[],
                        %box_lists.1 : __torch__.detectron2.structures.boxes.Boxes[]):
                    %366 : bool = prim::Constant[value=0]()
                    %357 : Function = prim::Constant[name="nonzero_tuple"]()
                    %335 : Function = prim::Constant[name="assign_boxes_to_levels"]()
                    %237 : Function = prim::Constant[name="convert_boxes_to_pooler_format"]()
                    %65 : Function = prim::Constant[name="_create_zeros"]()
                    %54 : NoneType = prim::Constant() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:33
                    %41 : str = prim::Constant[value="unequal value, x[0] batch dim 0 is {}, but box_list has length {}"]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:236:12
                    %32 : Function = prim::Constant[name="assert_fx_safe"]()
                    %27 : str = prim::Constant[value="unequal value, num_level_assignments={}, but x is list of {} Tensors"]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:230:12
                    %6 : Function = prim::Constant[name="is_fx_tracing"]()
                    %level.1 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:32
                    %level.7 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:50
                    %level.13 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:257:8
                    %level.19 : int = prim::Constant[value=3]() # /home/kelechi/detectron2/detectron2/modeling/poolers.py:257:8
                    %level_poolers.1 : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                    %num_level_assignments.1 : int = prim::CallMethod[name="__len__"](%level_poolers.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:221:32
                    %7 : bool = prim::CallFunction(%6) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:223:15
                    %9 : bool = aten::__not__(%7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:223:11
                    %x : Tensor[] = prim::If(%9) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:223:8
                      block0():
                        %x.7 : Tensor[] = prim::unchecked_cast(%x.1)
                        -> (%x.7)
                      block1():
                        -> (%x.1)
                    %24 : int = aten::len(%x) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:229:12
                    %26 : bool = aten::eq(%24, %num_level_assignments.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:229:12
                    %30 : int = aten::len(%x) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:231:39
                    %31 : str = aten::format(%27, %num_level_assignments.1, %30) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:230:12
                    %33 : Tensor = prim::CallFunction(%32, %26, %31) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:228:8
                    %35 : int = aten::len(%box_lists.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:12
                    %38 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:30
                    %39 : int = aten::size(%38, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:30
                    %40 : bool = aten::eq(%35, %39) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:235:12
                    %43 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:237:16
                    %44 : int = aten::size(%43, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:237:16
                    %46 : int = aten::len(%box_lists.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:237:30
                    %47 : str = aten::format(%41, %44, %46) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:236:12
                    %49 : Tensor = prim::CallFunction(%32, %40, %47) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:234:8
                    %51 : int = aten::len(%box_lists.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:240:11
                    %52 : bool = aten::eq(%51, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:240:11
                    %330 : Tensor = prim::If(%52) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:240:8
                      block0():
                        %56 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:39
                        %57 : int[] = aten::size(%56) # <string>:13:9
                        %59 : int = aten::__getitem__(%57, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:39
                        %output_size.1 : (int, int) = prim::GetAttr[name="output_size"](%self)
                        %61 : int, %62 : int = prim::TupleUnpack(%output_size.1)
                        %64 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:73
                        %66 : Tensor = prim::CallFunction(%65, %54, %59, %61, %62, %64) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:241:19
                        -> (%66)
                      block1():
                        %pooler_fmt_boxes.13 : Tensor = prim::CallFunction(%237, %box_lists.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:243:27
                        %239 : bool = aten::eq(%num_level_assignments.1, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:245:11
                        %405 : Tensor = prim::If(%239) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:245:8
                          block0():
                            %level_poolers.5 : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                            %_0.3 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers.5)
                            %252 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:246:41
                            %253 : Tensor = prim::CallMethod[name="forward"](%_0.3, %252, %pooler_fmt_boxes.13) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:246:19
                            -> (%253)
                          block1():
                            %min_level.5 : int = prim::GetAttr[name="min_level"](%self)
                            %max_level.5 : int = prim::GetAttr[name="max_level"](%self)
                            %canonical_box_size.5 : int = prim::GetAttr[name="canonical_box_size"](%self)
                            %canonical_level.5 : int = prim::GetAttr[name="canonical_level"](%self)
                            %level_assignments.13 : Tensor = prim::CallFunction(%335, %box_lists.1, %min_level.5, %max_level.5, %canonical_box_size.5, %canonical_level.5) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:248:28
                            %337 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:252:23
                            %338 : int[] = aten::size(%337) # <string>:13:9
                            %num_channels.7 : int = aten::__getitem__(%338, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:252:23
                            %output_size.17 : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %output_size.21 : int = prim::TupleIndex(%output_size.17, %level.1)
                            %342 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:255:89
                            %output.15 : Tensor = prim::CallFunction(%65, %pooler_fmt_boxes.13, %num_channels.7, %output_size.21, %output_size.21, %342) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:255:17
                            %level_poolers.13 : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                            %_0.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers.13)
                            %_1.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="1"](%level_poolers.13)
                            %_2.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="2"](%level_poolers.13)
                            %_3.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="3"](%level_poolers.13)
                            %356 : Tensor = aten::eq(%level_assignments.13, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:33
                            %358 : Tensor[] = prim::CallFunction(%357, %356) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %inds.55 : Tensor = aten::__getitem__(%358, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %360 : Tensor?[] = prim::ListConstruct(%inds.55)
                            %pooler_fmt_boxes_level.31 : Tensor = aten::index(%pooler_fmt_boxes.13, %360) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:259:37
                            %363 : Tensor = aten::__getitem__(%x, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:46
                            %364 : Tensor = prim::CallMethod[name="forward"](%_0.11, %363, %pooler_fmt_boxes_level.31) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:39
                            %365 : Tensor?[] = prim::ListConstruct(%inds.55)
                            %367 : Tensor = aten::index_put_(%output.15, %365, %364, %366) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:12
                            %368 : Tensor = aten::eq(%level_assignments.13, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:33
                            %370 : Tensor[] = prim::CallFunction(%357, %368) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %inds.59 : Tensor = aten::__getitem__(%370, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %372 : Tensor?[] = prim::ListConstruct(%inds.59)
                            %pooler_fmt_boxes_level.35 : Tensor = aten::index(%pooler_fmt_boxes.13, %372) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:259:37
                            %375 : Tensor = aten::__getitem__(%x, %level.7) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:46
                            %376 : Tensor = prim::CallMethod[name="forward"](%_1.11, %375, %pooler_fmt_boxes_level.35) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:39
                            %377 : Tensor?[] = prim::ListConstruct(%inds.59)
                            %379 : Tensor = aten::index_put_(%output.15, %377, %376, %366) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:12
                            %380 : Tensor = aten::eq(%level_assignments.13, %level.13) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:33
                            %382 : Tensor[] = prim::CallFunction(%357, %380) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %inds.63 : Tensor = aten::__getitem__(%382, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %384 : Tensor?[] = prim::ListConstruct(%inds.63)
                            %pooler_fmt_boxes_level.39 : Tensor = aten::index(%pooler_fmt_boxes.13, %384) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:259:37
                            %387 : Tensor = aten::__getitem__(%x, %level.13) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:46
                            %388 : Tensor = prim::CallMethod[name="forward"](%_2.11, %387, %pooler_fmt_boxes_level.39) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:39
                            %389 : Tensor?[] = prim::ListConstruct(%inds.63)
                            %391 : Tensor = aten::index_put_(%output.15, %389, %388, %366) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:12
                            %392 : Tensor = aten::eq(%level_assignments.13, %level.19) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:33
                            %394 : Tensor[] = prim::CallFunction(%357, %392) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %inds.67 : Tensor = aten::__getitem__(%394, %level.1) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:258:19
                            %396 : Tensor?[] = prim::ListConstruct(%inds.67)
                            %pooler_fmt_boxes_level.43 : Tensor = aten::index(%pooler_fmt_boxes.13, %396) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:259:37
                            %399 : Tensor = aten::__getitem__(%x, %level.19) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:46
                            %400 : Tensor = prim::CallMethod[name="forward"](%_3.11, %399, %pooler_fmt_boxes_level.43) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:39
                            %401 : Tensor?[] = prim::ListConstruct(%inds.67)
                            %403 : Tensor = aten::index_put_(%output.15, %401, %400, %366) # /home/kelechi/detectron2/detectron2/modeling/poolers.py:261:12
                            -> (%output.15)
                        -> (%405)
                    return (%330)
              
                }
              }
              submodules {
                module __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList {
                  parameters {
                  }
                  attributes {
                    _is_full_backward_hook = None
                    0 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x786b810>
                    1 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x74fdc60>
                    2 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x757a370>
                    3 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x7443d50>
                  }
                  methods {
                    method __len__ {
                      graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList):
                        %1 : int = prim::Constant[value=4]() # <string>:2:10
                        return (%1)
                  
                    }
                  }
                  submodules {
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (14, 14)
                        spatial_scale = 0.25
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %47 : Function = prim::Constant[name="roi_align"]()
                            %20 : NoneType = prim::Constant()
                            %61 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%61, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %23 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%23) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %35 : int = prim::dtype(%input)
                            %39 : Tensor = aten::to(%rois.1, %35, %15, %15, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %44 : int, %45 : int = prim::TupleUnpack(%output_size)
                            %46 : int[] = prim::ListConstruct(%44, %45)
                            %48 : Tensor = prim::CallFunction(%47, %input, %39, %46, %spatial_scale, %sampling_ratio, %aligned) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:58:15
                            return (%48)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (14, 14)
                        spatial_scale = 0.125
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %47 : Function = prim::Constant[name="roi_align"]()
                            %20 : NoneType = prim::Constant()
                            %61 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%61, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %23 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%23) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %35 : int = prim::dtype(%input)
                            %39 : Tensor = aten::to(%rois.1, %35, %15, %15, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %44 : int, %45 : int = prim::TupleUnpack(%output_size)
                            %46 : int[] = prim::ListConstruct(%44, %45)
                            %48 : Tensor = prim::CallFunction(%47, %input, %39, %46, %spatial_scale, %sampling_ratio, %aligned) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:58:15
                            return (%48)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (14, 14)
                        spatial_scale = 0.0625
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %47 : Function = prim::Constant[name="roi_align"]()
                            %20 : NoneType = prim::Constant()
                            %61 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%61, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %23 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%23) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %35 : int = prim::dtype(%input)
                            %39 : Tensor = aten::to(%rois.1, %35, %15, %15, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %44 : int, %45 : int = prim::TupleUnpack(%output_size)
                            %46 : int[] = prim::ListConstruct(%44, %45)
                            %48 : Tensor = prim::CallFunction(%47, %input, %39, %46, %spatial_scale, %sampling_ratio, %aligned) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:58:15
                            return (%48)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (14, 14)
                        spatial_scale = 0.03125
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %47 : Function = prim::Constant[name="roi_align"]()
                            %20 : NoneType = prim::Constant()
                            %61 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%61, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %23 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%23) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %35 : int = prim::dtype(%input)
                            %39 : Tensor = aten::to(%rois.1, %35, %15, %15, %20) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %44 : int, %45 : int = prim::TupleUnpack(%output_size)
                            %46 : int[] = prim::ListConstruct(%44, %45)
                            %48 : Tensor = prim::CallFunction(%47, %input, %39, %46, %spatial_scale, %sampling_ratio, %aligned) # /home/kelechi/detectron2/detectron2/layers/roi_align.py:58:15
                            return (%48)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                vis_period = 0
                loss_weight = 1.
                mask_fcn1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d object at 0x738f3c0>
                mask_fcn2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d object at 0x784d490>
                mask_fcn3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d object at 0x9625f80>
                mask_fcn4 = <__torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d object at 0x9621930>
                deconv = <__torch__.torch.nn.modules.conv.ConvTranspose2d object at 0x7856860>
                deconv_relu = <__torch__.torch.nn.modules.activation.ReLU object at 0x746c6a0>
                predictor = <__torch__.detectron2.layers.wrappers.___torch_mangle_42.Conv2d object at 0x75d09d0>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead,
                        %x.1 : Tensor,
                        %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                    %10 : Function = prim::Constant[name="mask_rcnn_inference"]()
                    %x.5 : Tensor = prim::CallMethod[name="layers"](%self, %x.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/mask_head.py:197:12
                    %11 : NoneType = prim::CallFunction(%10, %x.5, %instances.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/mask_head.py:201:12
                    return (%instances.1)
              
                }
                method layers {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead,
                        %x.1 : Tensor):
                    %30 : NoneType = prim::Constant()
                    %mask_fcn1 : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d = prim::GetAttr[name="mask_fcn1"](%self)
                    %mask_fcn2 : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d = prim::GetAttr[name="mask_fcn2"](%self)
                    %mask_fcn3 : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d = prim::GetAttr[name="mask_fcn3"](%self)
                    %mask_fcn4 : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d = prim::GetAttr[name="mask_fcn4"](%self)
                    %deconv : __torch__.torch.nn.modules.conv.ConvTranspose2d = prim::GetAttr[name="deconv"](%self)
                    %deconv_relu : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="deconv_relu"](%self)
                    %predictor : __torch__.detectron2.layers.wrappers.___torch_mangle_42.Conv2d = prim::GetAttr[name="predictor"](%self)
                    %x.5 : Tensor = prim::CallMethod[name="forward"](%mask_fcn1, %x.1) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.9 : Tensor = prim::CallMethod[name="forward"](%mask_fcn2, %x.5) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.13 : Tensor = prim::CallMethod[name="forward"](%mask_fcn3, %x.9) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.17 : Tensor = prim::CallMethod[name="forward"](%mask_fcn4, %x.13) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.21 : Tensor = prim::CallMethod[name="forward"](%deconv, %x.17, %30) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.25 : Tensor = prim::CallMethod[name="forward"](%deconv_relu, %x.21) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.29 : Tensor = prim::CallMethod[name="forward"](%predictor, %x.25) # /home/kelechi/detectron2/detectron2/modeling/roi_heads/mask_head.py:289:16
                    return (%x.29)
              
                }
                method __len__ {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead):
                    %1 : int = prim::Constant[value=7]() # <string>:2:10
                    return (%1)
              
                }
              }
              submodules {
                module __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0x7858e50>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:148:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0x753d830>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:148:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0x74ff110>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:148:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0x73ba660>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:148:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.torch.nn.modules.conv.ConvTranspose2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = True
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.conv.ConvTranspose2d,
                            %input.1 : Tensor,
                            %output_size.1 : int[]?):
                        %27 : int = prim::Constant[value=1]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:946:30
                        %20 : int = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:945:45
                        %num_spatial_dims.1 : int = prim::Constant[value=2]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:943:27
                        %30 : int[] = prim::ListConstruct(%num_spatial_dims.1, %num_spatial_dims.1)
                        %31 : int[] = prim::ListConstruct(%20, %20)
                        %32 : int[] = prim::ListConstruct(%num_spatial_dims.1, %num_spatial_dims.1)
                        %33 : int[] = prim::ListConstruct(%27, %27)
                        %output_padding.1 : int[] = prim::CallMethod[name="_output_padding"](%self, %input.1, %output_size.1, %30, %31, %32, %num_spatial_dims.1, %33) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:944:25
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %49 : int[] = prim::ListConstruct(%num_spatial_dims.1, %num_spatial_dims.1)
                        %50 : int[] = prim::ListConstruct(%20, %20)
                        %51 : int[] = prim::ListConstruct(%27, %27)
                        %52 : Tensor = aten::conv_transpose2d(%input.1, %weight, %bias, %49, %50, %output_padding.1, %27, %51) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:948:15
                        return (%52)
                  
                    }
                    method _output_padding {
                      graph(%self : __torch__.torch.nn.modules.conv.ConvTranspose2d,
                            %input.1 : Tensor,
                            %output_size.1 : int[]?,
                            %stride.1 : int[],
                            %padding.1 : int[],
                            %kernel_size.1 : int[],
                            %num_spatial_dims.1 : int,
                            %dilation.1 : int[]?):
                        %140 : str = prim::Constant[value="requested an output size of {}, but valid sizes range from {} to {} (for an input of {})"]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:656:24
                        %68 : bool = prim::Constant[value=1]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:643:12
                        %61 : str = prim::Constant[value="builtins.ValueError"]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:637:22
                        %50 : str = prim::Constant[value="ConvTranspose{}D: for {}D input, output_size must have {} or {} elements (got {})"]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:638:20
                        %11 : int = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:630:26
                        %9 : NoneType = prim::Constant() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:629:26
                        %21 : int = prim::Constant[value=2]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:632:62
                        %26 : int = prim::Constant[value=1]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:633:59
                        %10 : bool = aten::__is__(%output_size.1, %9) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:629:11
                        %ret : int[] = prim::If(%10) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:629:8
                          block0():
                            %ret.1 : int[] = prim::ListConstruct(%11, %11)
                            -> (%ret.1)
                          block1():
                            %output_size.7 : int[] = prim::unchecked_cast(%output_size.1)
                            %19 : int = aten::dim(%input.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:632:28
                            %22 : int = aten::add(%num_spatial_dims.1, %21) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:632:43
                            %has_batch_dim.1 : bool = aten::eq(%19, %22) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:632:28
                            %num_non_spatial_dims.1 : int = prim::If(%has_batch_dim.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:633:35
                              block0():
                                -> (%21)
                              block1():
                                -> (%26)
                            %29 : int = aten::len(%output_size.7) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:634:15
                            %32 : int = aten::add(%num_non_spatial_dims.1, %num_spatial_dims.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:634:35
                            %33 : bool = aten::eq(%29, %32) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:634:15
                            %output_size.47 : int[] = prim::If(%33) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:634:12
                              block0():
                                %output_size.15 : int[] = aten::slice(%output_size.7, %num_non_spatial_dims.1, %9, %26) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:635:30
                                -> (%output_size.15)
                              block1():
                                -> (%output_size.7)
                            %46 : int = aten::len(%output_size.47) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:636:15
                            %48 : bool = aten::ne(%46, %num_spatial_dims.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:636:15
                             = prim::If(%48) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:636:12
                              block0():
                                %53 : int = aten::dim(%input.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:638:61
                                %57 : int = aten::add(%num_non_spatial_dims.1, %num_spatial_dims.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:638:21
                                %59 : int = aten::len(%output_size.47) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:638:21
                                %60 : str = aten::format(%50, %num_spatial_dims.1, %53, %num_spatial_dims.1, %57, %59) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:638:20
                                 = prim::RaiseException(%60, %61) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:637:16
                                -> ()
                              block1():
                                -> ()
                            %min_sizes.1 : int[] = prim::ListConstruct()
                            %max_sizes.1 : int[] = prim::ListConstruct()
                            %dilation.17 : int[]? = prim::Loop(%num_spatial_dims.1, %68, %dilation.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:643:12
                              block0(%d.1 : int, %dilation.15 : int[]?):
                                %73 : int = aten::add(%d.1, %num_non_spatial_dims.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:40
                                %74 : int = aten::size(%input.1, %73) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:29
                                %75 : int = aten::sub(%74, %26) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:29
                                %78 : int = aten::__getitem__(%stride.1, %d.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:73
                                %79 : int = aten::mul(%75, %78) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:29
                                %82 : int = aten::__getitem__(%padding.1, %d.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:645:32
                                %83 : int = aten::mul(%21, %82) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:645:28
                                %84 : int = aten::sub(%79, %83) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:29
                                %87 : bool = aten::__isnot__(%dilation.15, %9) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:646:44
                                %94 : int, %dilation.13 : int[]? = prim::If(%87) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:646:29
                                  block0():
                                    %dilation.7 : int[] = prim::unchecked_cast(%dilation.15)
                                    %93 : int = aten::__getitem__(%dilation.7, %d.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:646:29
                                    -> (%93, %dilation.7)
                                  block1():
                                    -> (%26, %dilation.15)
                                %97 : int = aten::__getitem__(%kernel_size.1, %d.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:646:76
                                %98 : int = aten::sub(%97, %26) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:646:76
                                %99 : int = aten::mul(%94, %98) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:646:29
                                %100 : int = aten::add(%84, %99) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:29
                                %dim_size.1 : int = aten::add(%100, %26) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:29
                                %104 : int[] = aten::append(%min_sizes.1, %dim_size.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:647:16
                                %108 : int = aten::__getitem__(%min_sizes.1, %d.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:648:33
                                %111 : int = aten::__getitem__(%stride.1, %d.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:648:48
                                %112 : int = aten::add(%108, %111) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:648:33
                                %113 : int = aten::sub(%112, %26) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:648:33
                                %114 : int[] = aten::append(%max_sizes.1, %113) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:648:16
                                -> (%68, %dilation.13)
                            %116 : int = aten::len(%output_size.47) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:650:27
                             = prim::Loop(%116, %68) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:650:12
                              block0(%i.1 : int):
                                %size.1 : int = aten::__getitem__(%output_size.47, %i.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:651:23
                                %min_size.1 : int = aten::__getitem__(%min_sizes.1, %i.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:652:27
                                %max_size.1 : int = aten::__getitem__(%max_sizes.1, %i.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:653:27
                                %132 : bool = aten::lt(%size.1, %min_size.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:654:19
                                %139 : bool = prim::If(%132) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:654:19
                                  block0():
                                    -> (%68)
                                  block1():
                                    %137 : bool = aten::gt(%size.1, %max_size.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:654:38
                                    -> (%137)
                                 = prim::If(%139) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:654:16
                                  block0():
                                    %145 : int[] = aten::size(%input.1) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:656:25
                                    %148 : int[] = aten::slice(%145, %21, %9, %26) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:656:25
                                    %149 : str = aten::format(%140, %output_size.47, %min_sizes.1, %max_sizes.1, %148) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:656:24
                                     = prim::RaiseException(%149, %61) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:655:20
                                    -> ()
                                  block1():
                                    -> ()
                                -> (%68)
                            %res.1 : int[] = prim::ListConstruct()
                             = prim::Loop(%num_spatial_dims.1, %68) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:660:12
                              block0(%d.17 : int):
                                %161 : int = aten::__getitem__(%output_size.47, %d.17) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:661:27
                                %164 : int = aten::__getitem__(%min_sizes.1, %d.17) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:661:44
                                %165 : int = aten::sub(%161, %164) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:661:27
                                %166 : int[] = aten::append(%res.1, %165) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/conv.py:661:16
                                -> (%68)
                            -> (%res.1)
                        return (%ret)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.activation.ReLU {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                            %input.1 : Tensor):
                        %4 : Function = prim::Constant[name="relu"]()
                        %3 : bool = prim::Constant[value=0]() # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:37
                        %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/kelechi/miniconda3/envs/apollo/lib/python3.8/site-packages/torch/nn/modules/activation.py:104:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_42.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_42.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:52
                        %8 : int = prim::Constant[value=1]() # /home/kelechi/detectron2/detectron2/layers/wrappers.py:143:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/kelechi/detectron2/detectron2/layers/wrappers.py:142:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
